{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from deap import tools\n",
    "from deap import base, creator\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing import Pool\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation,AlphaDropout\n",
    "from keras.optimizers import adam, SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data'\n",
    "german_data = os.path.join(data_root,'GermanCreditInput.xls')\n",
    "german_label = os.path.join(data_root,'GermanCreditOutputClass1columnknn.xls')\n",
    "australian_dataset = os.path.join(data_root,'australian dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_config = {\n",
    "    'train_cycles':600,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape : (1000, 30)\n",
      "Dataset Labels Shape : (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(pd.read_excel(german_data,header=None))\n",
    "y_data = np.array(pd.read_excel(german_label,header=None))\n",
    "print('Dataset Shape : {}\\nDataset Labels Shape : {}'.format(x_data.shape,y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "mx = MinMaxScaler()\n",
    "mx.fit(x_data)\n",
    "p_x_data = mx.transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/600\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.7289 - acc: 0.6422 - val_loss: 0.5541 - val_acc: 0.7000\n",
      "Epoch 2/600\n",
      "900/900 [==============================] - 1s 669us/step - loss: 0.6188 - acc: 0.6956 - val_loss: 0.6689 - val_acc: 0.7000\n",
      "Epoch 3/600\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.5771 - acc: 0.7067 - val_loss: 0.6364 - val_acc: 0.7100\n",
      "Epoch 4/600\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.5840 - acc: 0.7144 - val_loss: 0.5931 - val_acc: 0.7300\n",
      "Epoch 5/600\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.5663 - acc: 0.7178 - val_loss: 0.5025 - val_acc: 0.7600\n",
      "Epoch 6/600\n",
      "900/900 [==============================] - 1s 819us/step - loss: 0.5591 - acc: 0.7200 - val_loss: 0.5805 - val_acc: 0.7400\n",
      "Epoch 7/600\n",
      "900/900 [==============================] - 1s 845us/step - loss: 0.5412 - acc: 0.7200 - val_loss: 0.6264 - val_acc: 0.7400\n",
      "Epoch 8/600\n",
      "900/900 [==============================] - 1s 886us/step - loss: 0.5335 - acc: 0.7344 - val_loss: 0.5956 - val_acc: 0.7300\n",
      "Epoch 9/600\n",
      "900/900 [==============================] - 1s 865us/step - loss: 0.5083 - acc: 0.7567 - val_loss: 0.5665 - val_acc: 0.7500\n",
      "Epoch 10/600\n",
      "900/900 [==============================] - 1s 868us/step - loss: 0.5349 - acc: 0.7400 - val_loss: 0.6225 - val_acc: 0.7400\n",
      "Epoch 11/600\n",
      "900/900 [==============================] - 1s 885us/step - loss: 0.5357 - acc: 0.7489 - val_loss: 0.4586 - val_acc: 0.7800\n",
      "Epoch 12/600\n",
      "900/900 [==============================] - 1s 861us/step - loss: 0.5177 - acc: 0.7511 - val_loss: 0.4718 - val_acc: 0.7700\n",
      "Epoch 13/600\n",
      "900/900 [==============================] - 1s 870us/step - loss: 0.5196 - acc: 0.7389 - val_loss: 0.5285 - val_acc: 0.7700\n",
      "Epoch 14/600\n",
      "900/900 [==============================] - 1s 845us/step - loss: 0.5079 - acc: 0.7511 - val_loss: 0.4527 - val_acc: 0.8000\n",
      "Epoch 15/600\n",
      "900/900 [==============================] - 1s 863us/step - loss: 0.5080 - acc: 0.7522 - val_loss: 0.4658 - val_acc: 0.7600\n",
      "Epoch 16/600\n",
      "900/900 [==============================] - 1s 850us/step - loss: 0.5123 - acc: 0.7456 - val_loss: 0.4777 - val_acc: 0.7500\n",
      "Epoch 17/600\n",
      "900/900 [==============================] - 1s 858us/step - loss: 0.5074 - acc: 0.7489 - val_loss: 0.6342 - val_acc: 0.7600\n",
      "Epoch 18/600\n",
      "900/900 [==============================] - 1s 867us/step - loss: 0.5033 - acc: 0.7578 - val_loss: 0.4281 - val_acc: 0.8100\n",
      "Epoch 19/600\n",
      "900/900 [==============================] - 1s 889us/step - loss: 0.5138 - acc: 0.7456 - val_loss: 0.5355 - val_acc: 0.7500\n",
      "Epoch 20/600\n",
      "900/900 [==============================] - 1s 898us/step - loss: 0.4945 - acc: 0.7567 - val_loss: 0.4684 - val_acc: 0.7400\n",
      "Epoch 21/600\n",
      "900/900 [==============================] - 1s 904us/step - loss: 0.5036 - acc: 0.7444 - val_loss: 0.5451 - val_acc: 0.7700\n",
      "Epoch 22/600\n",
      "900/900 [==============================] - 1s 561us/step - loss: 0.5098 - acc: 0.7567 - val_loss: 0.5113 - val_acc: 0.7400\n",
      "Epoch 23/600\n",
      "900/900 [==============================] - 1s 659us/step - loss: 0.4818 - acc: 0.7778 - val_loss: 0.4332 - val_acc: 0.7800\n",
      "Epoch 24/600\n",
      "900/900 [==============================] - 1s 645us/step - loss: 0.4915 - acc: 0.7522 - val_loss: 0.4326 - val_acc: 0.8100\n",
      "Epoch 25/600\n",
      "900/900 [==============================] - 1s 665us/step - loss: 0.4809 - acc: 0.7778 - val_loss: 0.4452 - val_acc: 0.8000\n",
      "Epoch 26/600\n",
      "900/900 [==============================] - 1s 641us/step - loss: 0.5054 - acc: 0.7511 - val_loss: 0.5268 - val_acc: 0.7600\n",
      "Epoch 27/600\n",
      "900/900 [==============================] - 1s 656us/step - loss: 0.5017 - acc: 0.7589 - val_loss: 0.4554 - val_acc: 0.7800\n",
      "Epoch 28/600\n",
      "900/900 [==============================] - 1s 636us/step - loss: 0.4912 - acc: 0.7556 - val_loss: 0.4619 - val_acc: 0.7700\n",
      "Epoch 29/600\n",
      "900/900 [==============================] - 1s 651us/step - loss: 0.4954 - acc: 0.7500 - val_loss: 0.4763 - val_acc: 0.7900\n",
      "Epoch 30/600\n",
      "900/900 [==============================] - 1s 639us/step - loss: 0.4808 - acc: 0.7689 - val_loss: 0.4559 - val_acc: 0.7900\n",
      "Epoch 31/600\n",
      "900/900 [==============================] - 1s 662us/step - loss: 0.4927 - acc: 0.7711 - val_loss: 0.4626 - val_acc: 0.7700\n",
      "Epoch 32/600\n",
      "900/900 [==============================] - 1s 644us/step - loss: 0.4877 - acc: 0.7633 - val_loss: 0.4278 - val_acc: 0.8300\n",
      "Epoch 33/600\n",
      "900/900 [==============================] - 1s 656us/step - loss: 0.4916 - acc: 0.7711 - val_loss: 0.6152 - val_acc: 0.7600\n",
      "Epoch 34/600\n",
      "900/900 [==============================] - 1s 651us/step - loss: 0.4746 - acc: 0.7833 - val_loss: 0.4655 - val_acc: 0.7700\n",
      "Epoch 35/600\n",
      "900/900 [==============================] - 1s 619us/step - loss: 0.4762 - acc: 0.7744 - val_loss: 0.4568 - val_acc: 0.7800\n",
      "Epoch 36/600\n",
      "900/900 [==============================] - 1s 655us/step - loss: 0.4798 - acc: 0.7589 - val_loss: 0.4992 - val_acc: 0.7600\n",
      "Epoch 37/600\n",
      "900/900 [==============================] - 1s 673us/step - loss: 0.4974 - acc: 0.7556 - val_loss: 0.6088 - val_acc: 0.7600\n",
      "Epoch 38/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.4611 - acc: 0.7822 - val_loss: 0.5402 - val_acc: 0.7500\n",
      "Epoch 39/600\n",
      "900/900 [==============================] - 1s 637us/step - loss: 0.4762 - acc: 0.7522 - val_loss: 0.4840 - val_acc: 0.7400\n",
      "Epoch 40/600\n",
      "900/900 [==============================] - 1s 646us/step - loss: 0.4795 - acc: 0.7656 - val_loss: 0.5137 - val_acc: 0.7800\n",
      "Epoch 41/600\n",
      "900/900 [==============================] - 1s 664us/step - loss: 0.4699 - acc: 0.7867 - val_loss: 0.4855 - val_acc: 0.7700\n",
      "Epoch 42/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.4808 - acc: 0.7644 - val_loss: 0.4987 - val_acc: 0.7600\n",
      "Epoch 43/600\n",
      "900/900 [==============================] - 1s 660us/step - loss: 0.4722 - acc: 0.7678 - val_loss: 0.4871 - val_acc: 0.7700\n",
      "Epoch 44/600\n",
      "900/900 [==============================] - 1s 652us/step - loss: 0.4808 - acc: 0.7744 - val_loss: 0.4669 - val_acc: 0.7700\n",
      "Epoch 45/600\n",
      "900/900 [==============================] - 1s 666us/step - loss: 0.4833 - acc: 0.7600 - val_loss: 0.4875 - val_acc: 0.7800\n",
      "Epoch 46/600\n",
      "900/900 [==============================] - 1s 658us/step - loss: 0.4834 - acc: 0.7622 - val_loss: 0.4863 - val_acc: 0.7700\n",
      "Epoch 47/600\n",
      "900/900 [==============================] - 1s 653us/step - loss: 0.4742 - acc: 0.7644 - val_loss: 0.4812 - val_acc: 0.7700\n",
      "Epoch 48/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.4736 - acc: 0.7633 - val_loss: 0.5392 - val_acc: 0.7600\n",
      "Epoch 49/600\n",
      "900/900 [==============================] - 1s 655us/step - loss: 0.4677 - acc: 0.7678 - val_loss: 0.4660 - val_acc: 0.7500\n",
      "Epoch 50/600\n",
      "900/900 [==============================] - 1s 652us/step - loss: 0.4698 - acc: 0.7811 - val_loss: 0.4715 - val_acc: 0.7700\n",
      "Epoch 51/600\n",
      "900/900 [==============================] - 1s 604us/step - loss: 0.4794 - acc: 0.7633 - val_loss: 0.4665 - val_acc: 0.7400\n",
      "Epoch 52/600\n",
      "900/900 [==============================] - 1s 663us/step - loss: 0.4675 - acc: 0.7722 - val_loss: 0.5027 - val_acc: 0.7400\n",
      "Epoch 53/600\n",
      "900/900 [==============================] - 1s 658us/step - loss: 0.4652 - acc: 0.7722 - val_loss: 0.4693 - val_acc: 0.7800\n",
      "Epoch 54/600\n",
      "900/900 [==============================] - 1s 666us/step - loss: 0.4849 - acc: 0.7511 - val_loss: 0.4927 - val_acc: 0.7900\n",
      "Epoch 55/600\n",
      "900/900 [==============================] - 1s 672us/step - loss: 0.4721 - acc: 0.7633 - val_loss: 0.5008 - val_acc: 0.7700\n",
      "Epoch 56/600\n",
      "900/900 [==============================] - 1s 598us/step - loss: 0.4891 - acc: 0.7489 - val_loss: 0.4820 - val_acc: 0.7500\n",
      "Epoch 57/600\n",
      "900/900 [==============================] - 1s 676us/step - loss: 0.4687 - acc: 0.7556 - val_loss: 0.4863 - val_acc: 0.7800\n",
      "Epoch 58/600\n",
      "900/900 [==============================] - 1s 632us/step - loss: 0.4709 - acc: 0.7678 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 59/600\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.4835 - acc: 0.7522 - val_loss: 0.4691 - val_acc: 0.7600\n",
      "Epoch 60/600\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.4614 - acc: 0.7533 - val_loss: 0.5969 - val_acc: 0.7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.4678 - acc: 0.7644 - val_loss: 0.5437 - val_acc: 0.7800\n",
      "Epoch 62/600\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.4782 - acc: 0.7711 - val_loss: 0.4682 - val_acc: 0.7800\n",
      "Epoch 63/600\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.4666 - acc: 0.7667 - val_loss: 0.4609 - val_acc: 0.7800\n",
      "Epoch 64/600\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.4697 - acc: 0.7711 - val_loss: 0.4537 - val_acc: 0.7800\n",
      "Epoch 65/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.4624 - acc: 0.7744 - val_loss: 0.4730 - val_acc: 0.8000\n",
      "Epoch 66/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.4650 - acc: 0.7733 - val_loss: 0.4868 - val_acc: 0.7600\n",
      "Epoch 67/600\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.4523 - acc: 0.7922 - val_loss: 0.4738 - val_acc: 0.7900\n",
      "Epoch 68/600\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.4439 - acc: 0.7889 - val_loss: 0.4575 - val_acc: 0.7800\n",
      "Epoch 69/600\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.4578 - acc: 0.7800 - val_loss: 0.4629 - val_acc: 0.7600\n",
      "Epoch 70/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.4719 - acc: 0.7733 - val_loss: 0.5233 - val_acc: 0.7800\n",
      "Epoch 71/600\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.4647 - acc: 0.7722 - val_loss: 0.4918 - val_acc: 0.7700\n",
      "Epoch 72/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.4635 - acc: 0.7600 - val_loss: 0.4820 - val_acc: 0.8000\n",
      "Epoch 73/600\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.4548 - acc: 0.7822 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 74/600\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.4673 - acc: 0.7711 - val_loss: 0.4717 - val_acc: 0.8100\n",
      "Epoch 75/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.4603 - acc: 0.7811 - val_loss: 0.5368 - val_acc: 0.8000\n",
      "Epoch 76/600\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.4715 - acc: 0.7656 - val_loss: 0.5114 - val_acc: 0.8000\n",
      "Epoch 77/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.4689 - acc: 0.7656 - val_loss: 0.5013 - val_acc: 0.8100\n",
      "Epoch 78/600\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.4597 - acc: 0.7711 - val_loss: 0.5628 - val_acc: 0.7800\n",
      "Epoch 79/600\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.4621 - acc: 0.7744 - val_loss: 0.4845 - val_acc: 0.7700\n",
      "Epoch 80/600\n",
      "900/900 [==============================] - 1s 707us/step - loss: 0.4566 - acc: 0.7800 - val_loss: 0.4701 - val_acc: 0.7700\n",
      "Epoch 81/600\n",
      "900/900 [==============================] - 1s 716us/step - loss: 0.4491 - acc: 0.7778 - val_loss: 0.4928 - val_acc: 0.8000\n",
      "Epoch 82/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.4664 - acc: 0.7589 - val_loss: 0.4567 - val_acc: 0.8000\n",
      "Epoch 83/600\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.4648 - acc: 0.7767 - val_loss: 0.4869 - val_acc: 0.8100\n",
      "Epoch 84/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.4448 - acc: 0.7978 - val_loss: 0.4623 - val_acc: 0.7600\n",
      "Epoch 85/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.4664 - acc: 0.7722 - val_loss: 0.4442 - val_acc: 0.8000\n",
      "Epoch 86/600\n",
      "900/900 [==============================] - 1s 794us/step - loss: 0.4544 - acc: 0.7844 - val_loss: 0.4423 - val_acc: 0.7900\n",
      "Epoch 87/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.4626 - acc: 0.7700 - val_loss: 0.4475 - val_acc: 0.7800\n",
      "Epoch 88/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.4478 - acc: 0.7889 - val_loss: 0.4505 - val_acc: 0.8100\n",
      "Epoch 89/600\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.4548 - acc: 0.7767 - val_loss: 0.4509 - val_acc: 0.8300\n",
      "Epoch 90/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.4514 - acc: 0.7789 - val_loss: 0.4535 - val_acc: 0.8000\n",
      "Epoch 91/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.4409 - acc: 0.7989 - val_loss: 0.4655 - val_acc: 0.8100\n",
      "Epoch 92/600\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.4534 - acc: 0.7711 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 93/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.4523 - acc: 0.7800 - val_loss: 0.5257 - val_acc: 0.8100\n",
      "Epoch 94/600\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.4303 - acc: 0.7922 - val_loss: 0.5145 - val_acc: 0.8000\n",
      "Epoch 95/600\n",
      "900/900 [==============================] - 1s 784us/step - loss: 0.4472 - acc: 0.7878 - val_loss: 0.4847 - val_acc: 0.7900\n",
      "Epoch 96/600\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.4539 - acc: 0.7711 - val_loss: 0.5025 - val_acc: 0.8000\n",
      "Epoch 97/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.4447 - acc: 0.7800 - val_loss: 0.4735 - val_acc: 0.7900\n",
      "Epoch 98/600\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.4413 - acc: 0.7811 - val_loss: 0.5281 - val_acc: 0.8000\n",
      "Epoch 99/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.4421 - acc: 0.7933 - val_loss: 0.4912 - val_acc: 0.8100\n",
      "Epoch 100/600\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.4478 - acc: 0.7833 - val_loss: 0.4870 - val_acc: 0.8100\n",
      "Epoch 101/600\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.4556 - acc: 0.7789 - val_loss: 0.4798 - val_acc: 0.8100\n",
      "Epoch 102/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.4548 - acc: 0.7778 - val_loss: 0.4971 - val_acc: 0.8000\n",
      "Epoch 103/600\n",
      "900/900 [==============================] - 1s 722us/step - loss: 0.4529 - acc: 0.7722 - val_loss: 0.4602 - val_acc: 0.8300\n",
      "Epoch 104/600\n",
      "900/900 [==============================] - 1s 726us/step - loss: 0.4542 - acc: 0.7778 - val_loss: 0.4401 - val_acc: 0.8000\n",
      "Epoch 105/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.4457 - acc: 0.7933 - val_loss: 0.4652 - val_acc: 0.8100\n",
      "Epoch 106/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.4486 - acc: 0.7989 - val_loss: 0.5123 - val_acc: 0.8300\n",
      "Epoch 107/600\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.4328 - acc: 0.8011 - val_loss: 0.4649 - val_acc: 0.7900\n",
      "Epoch 108/600\n",
      "900/900 [==============================] - 1s 815us/step - loss: 0.4466 - acc: 0.7944 - val_loss: 0.4638 - val_acc: 0.7900\n",
      "Epoch 109/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.4241 - acc: 0.8022 - val_loss: 0.4972 - val_acc: 0.8000\n",
      "Epoch 110/600\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.4456 - acc: 0.7822 - val_loss: 0.4906 - val_acc: 0.8000\n",
      "Epoch 111/600\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.4357 - acc: 0.7811 - val_loss: 0.4932 - val_acc: 0.7700\n",
      "Epoch 112/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.4301 - acc: 0.7822 - val_loss: 0.4863 - val_acc: 0.8100\n",
      "Epoch 113/600\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.4282 - acc: 0.8067 - val_loss: 0.5020 - val_acc: 0.7800\n",
      "Epoch 114/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.4420 - acc: 0.7900 - val_loss: 0.4335 - val_acc: 0.8200\n",
      "Epoch 115/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.4336 - acc: 0.8022 - val_loss: 0.4335 - val_acc: 0.8100\n",
      "Epoch 116/600\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.4288 - acc: 0.7878 - val_loss: 0.4411 - val_acc: 0.7500\n",
      "Epoch 117/600\n",
      "900/900 [==============================] - 1s 799us/step - loss: 0.4293 - acc: 0.8000 - val_loss: 0.5140 - val_acc: 0.7800\n",
      "Epoch 118/600\n",
      "900/900 [==============================] - 1s 811us/step - loss: 0.4347 - acc: 0.7978 - val_loss: 0.4426 - val_acc: 0.8100\n",
      "Epoch 119/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.4342 - acc: 0.7978 - val_loss: 0.4774 - val_acc: 0.8200\n",
      "Epoch 120/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.4275 - acc: 0.8133 - val_loss: 0.5022 - val_acc: 0.7700\n",
      "Epoch 121/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 769us/step - loss: 0.4444 - acc: 0.7967 - val_loss: 0.4472 - val_acc: 0.7900\n",
      "Epoch 122/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.4386 - acc: 0.7878 - val_loss: 0.4829 - val_acc: 0.8000\n",
      "Epoch 123/600\n",
      "900/900 [==============================] - 1s 726us/step - loss: 0.4419 - acc: 0.7900 - val_loss: 0.4805 - val_acc: 0.8000\n",
      "Epoch 124/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.4363 - acc: 0.8011 - val_loss: 0.4621 - val_acc: 0.8200\n",
      "Epoch 125/600\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.4424 - acc: 0.7933 - val_loss: 0.5001 - val_acc: 0.8200\n",
      "Epoch 126/600\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.4433 - acc: 0.7978 - val_loss: 0.4774 - val_acc: 0.8100\n",
      "Epoch 127/600\n",
      "900/900 [==============================] - 1s 716us/step - loss: 0.4263 - acc: 0.7989 - val_loss: 0.4283 - val_acc: 0.8200\n",
      "Epoch 128/600\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.4164 - acc: 0.7956 - val_loss: 0.4350 - val_acc: 0.8500\n",
      "Epoch 129/600\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.4095 - acc: 0.8000 - val_loss: 0.4645 - val_acc: 0.8400\n",
      "Epoch 130/600\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.4252 - acc: 0.7900 - val_loss: 0.4656 - val_acc: 0.8100\n",
      "Epoch 131/600\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.4282 - acc: 0.7944 - val_loss: 0.5017 - val_acc: 0.8100\n",
      "Epoch 132/600\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.4215 - acc: 0.8000 - val_loss: 0.4604 - val_acc: 0.8000\n",
      "Epoch 133/600\n",
      "900/900 [==============================] - 1s 700us/step - loss: 0.4272 - acc: 0.8022 - val_loss: 0.4959 - val_acc: 0.8100\n",
      "Epoch 134/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.4345 - acc: 0.7900 - val_loss: 0.4920 - val_acc: 0.8100\n",
      "Epoch 135/600\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.4281 - acc: 0.8000 - val_loss: 0.4945 - val_acc: 0.8200\n",
      "Epoch 136/600\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.4128 - acc: 0.8122 - val_loss: 0.4635 - val_acc: 0.8200\n",
      "Epoch 137/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.4162 - acc: 0.7989 - val_loss: 0.5083 - val_acc: 0.7800\n",
      "Epoch 138/600\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.4178 - acc: 0.8033 - val_loss: 0.4788 - val_acc: 0.8200\n",
      "Epoch 139/600\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.4166 - acc: 0.8078 - val_loss: 0.4615 - val_acc: 0.8000\n",
      "Epoch 140/600\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.4197 - acc: 0.8067 - val_loss: 0.4724 - val_acc: 0.8000\n",
      "Epoch 141/600\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.4148 - acc: 0.8067 - val_loss: 0.4688 - val_acc: 0.7900\n",
      "Epoch 142/600\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.4160 - acc: 0.8256 - val_loss: 0.4544 - val_acc: 0.8200\n",
      "Epoch 143/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.4272 - acc: 0.7967 - val_loss: 0.4658 - val_acc: 0.8200\n",
      "Epoch 144/600\n",
      "900/900 [==============================] - 1s 706us/step - loss: 0.4187 - acc: 0.7978 - val_loss: 0.4566 - val_acc: 0.8000\n",
      "Epoch 145/600\n",
      "900/900 [==============================] - 1s 708us/step - loss: 0.4094 - acc: 0.8156 - val_loss: 0.4842 - val_acc: 0.8100\n",
      "Epoch 146/600\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.4270 - acc: 0.7889 - val_loss: 0.5118 - val_acc: 0.7800\n",
      "Epoch 147/600\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.4150 - acc: 0.8067 - val_loss: 0.5224 - val_acc: 0.7900\n",
      "Epoch 148/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.4157 - acc: 0.8144 - val_loss: 0.4991 - val_acc: 0.8000\n",
      "Epoch 149/600\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.4124 - acc: 0.8111 - val_loss: 0.4543 - val_acc: 0.8100\n",
      "Epoch 150/600\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.3999 - acc: 0.8100 - val_loss: 0.4827 - val_acc: 0.8100\n",
      "Epoch 151/600\n",
      "900/900 [==============================] - 1s 696us/step - loss: 0.4154 - acc: 0.8156 - val_loss: 0.4727 - val_acc: 0.7800\n",
      "Epoch 152/600\n",
      "900/900 [==============================] - 1s 714us/step - loss: 0.4075 - acc: 0.8056 - val_loss: 0.4793 - val_acc: 0.7700\n",
      "Epoch 153/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.4159 - acc: 0.8056 - val_loss: 0.4698 - val_acc: 0.8000\n",
      "Epoch 154/600\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.3948 - acc: 0.8289 - val_loss: 0.5255 - val_acc: 0.8100\n",
      "Epoch 155/600\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.4219 - acc: 0.8000 - val_loss: 0.4770 - val_acc: 0.7700\n",
      "Epoch 156/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.4040 - acc: 0.8122 - val_loss: 0.4624 - val_acc: 0.7900\n",
      "Epoch 157/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.4242 - acc: 0.8022 - val_loss: 0.4515 - val_acc: 0.7900\n",
      "Epoch 158/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.4055 - acc: 0.8089 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 159/600\n",
      "900/900 [==============================] - 1s 722us/step - loss: 0.3937 - acc: 0.8267 - val_loss: 0.5118 - val_acc: 0.8000\n",
      "Epoch 160/600\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.4205 - acc: 0.8111 - val_loss: 0.5152 - val_acc: 0.7900\n",
      "Epoch 161/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.3995 - acc: 0.8289 - val_loss: 0.4953 - val_acc: 0.8200\n",
      "Epoch 162/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.4124 - acc: 0.8022 - val_loss: 0.4687 - val_acc: 0.8000\n",
      "Epoch 163/600\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.4062 - acc: 0.8067 - val_loss: 0.5256 - val_acc: 0.7700\n",
      "Epoch 164/600\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.3896 - acc: 0.8322 - val_loss: 0.4799 - val_acc: 0.8300\n",
      "Epoch 165/600\n",
      "900/900 [==============================] - 1s 719us/step - loss: 0.3944 - acc: 0.8122 - val_loss: 0.5035 - val_acc: 0.7600\n",
      "Epoch 166/600\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.3938 - acc: 0.8178 - val_loss: 0.4856 - val_acc: 0.7900\n",
      "Epoch 167/600\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.4005 - acc: 0.8211 - val_loss: 0.4444 - val_acc: 0.8300\n",
      "Epoch 168/600\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.4135 - acc: 0.8100 - val_loss: 0.4483 - val_acc: 0.8200\n",
      "Epoch 169/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.3994 - acc: 0.8100 - val_loss: 0.5402 - val_acc: 0.8000\n",
      "Epoch 170/600\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.3980 - acc: 0.8211 - val_loss: 0.5036 - val_acc: 0.8000\n",
      "Epoch 171/600\n",
      "900/900 [==============================] - 1s 753us/step - loss: 0.4008 - acc: 0.8300 - val_loss: 0.4909 - val_acc: 0.8100\n",
      "Epoch 172/600\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.4089 - acc: 0.8178 - val_loss: 0.5246 - val_acc: 0.7800\n",
      "Epoch 173/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.3980 - acc: 0.8256 - val_loss: 0.5603 - val_acc: 0.7800\n",
      "Epoch 174/600\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.3886 - acc: 0.8233 - val_loss: 0.5235 - val_acc: 0.8000\n",
      "Epoch 175/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.4017 - acc: 0.8056 - val_loss: 0.5029 - val_acc: 0.7600\n",
      "Epoch 176/600\n",
      "900/900 [==============================] - 1s 706us/step - loss: 0.3985 - acc: 0.8178 - val_loss: 0.5405 - val_acc: 0.7900\n",
      "Epoch 177/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.4088 - acc: 0.8078 - val_loss: 0.5265 - val_acc: 0.8000\n",
      "Epoch 178/600\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.3842 - acc: 0.8156 - val_loss: 0.5169 - val_acc: 0.8100\n",
      "Epoch 179/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.3927 - acc: 0.8333 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 180/600\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.3930 - acc: 0.8256 - val_loss: 0.5198 - val_acc: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.3836 - acc: 0.8278 - val_loss: 0.5318 - val_acc: 0.8100\n",
      "Epoch 182/600\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.3821 - acc: 0.8378 - val_loss: 0.4681 - val_acc: 0.8300\n",
      "Epoch 183/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.3875 - acc: 0.8244 - val_loss: 0.5053 - val_acc: 0.8200\n",
      "Epoch 184/600\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.3869 - acc: 0.8244 - val_loss: 0.5325 - val_acc: 0.8100\n",
      "Epoch 185/600\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.3851 - acc: 0.8289 - val_loss: 0.5236 - val_acc: 0.8100\n",
      "Epoch 186/600\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.3924 - acc: 0.8167 - val_loss: 0.5201 - val_acc: 0.8000\n",
      "Epoch 187/600\n",
      "900/900 [==============================] - 1s 826us/step - loss: 0.3815 - acc: 0.8167 - val_loss: 0.5279 - val_acc: 0.7600\n",
      "Epoch 188/600\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.3956 - acc: 0.8289 - val_loss: 0.5113 - val_acc: 0.7900\n",
      "Epoch 189/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.3962 - acc: 0.8200 - val_loss: 0.4667 - val_acc: 0.8100\n",
      "Epoch 190/600\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.3811 - acc: 0.8244 - val_loss: 0.5403 - val_acc: 0.7400\n",
      "Epoch 191/600\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.3684 - acc: 0.8456 - val_loss: 0.5521 - val_acc: 0.8400\n",
      "Epoch 192/600\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.3662 - acc: 0.8289 - val_loss: 0.5202 - val_acc: 0.7900\n",
      "Epoch 193/600\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.3943 - acc: 0.8200 - val_loss: 0.5107 - val_acc: 0.8200\n",
      "Epoch 194/600\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.3727 - acc: 0.8256 - val_loss: 0.4994 - val_acc: 0.7800\n",
      "Epoch 195/600\n",
      "900/900 [==============================] - 1s 719us/step - loss: 0.3729 - acc: 0.8278 - val_loss: 0.5479 - val_acc: 0.8100\n",
      "Epoch 196/600\n",
      "900/900 [==============================] - 1s 616us/step - loss: 0.3775 - acc: 0.8311 - val_loss: 0.5537 - val_acc: 0.7700\n",
      "Epoch 197/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.3673 - acc: 0.8333 - val_loss: 0.5702 - val_acc: 0.7700\n",
      "Epoch 198/600\n",
      "900/900 [==============================] - 1s 623us/step - loss: 0.3630 - acc: 0.8378 - val_loss: 0.5474 - val_acc: 0.7300\n",
      "Epoch 199/600\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.3759 - acc: 0.8311 - val_loss: 0.5494 - val_acc: 0.8200\n",
      "Epoch 200/600\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.3746 - acc: 0.8378 - val_loss: 0.5996 - val_acc: 0.8000\n",
      "Epoch 201/600\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.3462 - acc: 0.8389 - val_loss: 0.6445 - val_acc: 0.7400\n",
      "Epoch 202/600\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.3646 - acc: 0.8333 - val_loss: 0.5344 - val_acc: 0.7900\n",
      "Epoch 203/600\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.3754 - acc: 0.8244 - val_loss: 0.6824 - val_acc: 0.7800\n",
      "Epoch 204/600\n",
      "900/900 [==============================] - 1s 825us/step - loss: 0.3647 - acc: 0.8444 - val_loss: 0.6188 - val_acc: 0.7500\n",
      "Epoch 205/600\n",
      "900/900 [==============================] - 1s 795us/step - loss: 0.3690 - acc: 0.8333 - val_loss: 0.5411 - val_acc: 0.7800\n",
      "Epoch 206/600\n",
      "900/900 [==============================] - 1s 796us/step - loss: 0.3697 - acc: 0.8400 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 207/600\n",
      "900/900 [==============================] - 1s 774us/step - loss: 0.3851 - acc: 0.8256 - val_loss: 0.5374 - val_acc: 0.7700\n",
      "Epoch 208/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.3428 - acc: 0.8422 - val_loss: 0.5845 - val_acc: 0.8300\n",
      "Epoch 209/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.3642 - acc: 0.8267 - val_loss: 0.5403 - val_acc: 0.7800\n",
      "Epoch 210/600\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.3368 - acc: 0.8511 - val_loss: 0.5578 - val_acc: 0.8300\n",
      "Epoch 211/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.3703 - acc: 0.8333 - val_loss: 0.5675 - val_acc: 0.8100\n",
      "Epoch 212/600\n",
      "900/900 [==============================] - 1s 724us/step - loss: 0.3516 - acc: 0.8444 - val_loss: 0.5386 - val_acc: 0.8200\n",
      "Epoch 213/600\n",
      "900/900 [==============================] - 1s 710us/step - loss: 0.3679 - acc: 0.8311 - val_loss: 0.5870 - val_acc: 0.8000\n",
      "Epoch 214/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.3614 - acc: 0.8367 - val_loss: 0.5545 - val_acc: 0.8200\n",
      "Epoch 215/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.3632 - acc: 0.8322 - val_loss: 0.5452 - val_acc: 0.7900\n",
      "Epoch 216/600\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.3398 - acc: 0.8367 - val_loss: 0.5945 - val_acc: 0.8400\n",
      "Epoch 217/600\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.3750 - acc: 0.8322 - val_loss: 0.5795 - val_acc: 0.8000\n",
      "Epoch 218/600\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.3515 - acc: 0.8511 - val_loss: 0.5409 - val_acc: 0.8300\n",
      "Epoch 219/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.3549 - acc: 0.8378 - val_loss: 0.5299 - val_acc: 0.8000\n",
      "Epoch 220/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.3633 - acc: 0.8422 - val_loss: 0.4863 - val_acc: 0.8400\n",
      "Epoch 221/600\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.3614 - acc: 0.8411 - val_loss: 0.5253 - val_acc: 0.7700\n",
      "Epoch 222/600\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.3340 - acc: 0.8489 - val_loss: 0.5333 - val_acc: 0.8200\n",
      "Epoch 223/600\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.3533 - acc: 0.8378 - val_loss: 0.5280 - val_acc: 0.8000\n",
      "Epoch 224/600\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.3483 - acc: 0.8456 - val_loss: 0.5579 - val_acc: 0.8300\n",
      "Epoch 225/600\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.3332 - acc: 0.8656 - val_loss: 0.5633 - val_acc: 0.8000\n",
      "Epoch 226/600\n",
      "900/900 [==============================] - 1s 753us/step - loss: 0.3426 - acc: 0.8478 - val_loss: 0.5818 - val_acc: 0.7900\n",
      "Epoch 227/600\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.3509 - acc: 0.8611 - val_loss: 0.5777 - val_acc: 0.8000\n",
      "Epoch 228/600\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.3470 - acc: 0.8544 - val_loss: 0.5633 - val_acc: 0.8100\n",
      "Epoch 229/600\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.3239 - acc: 0.8567 - val_loss: 0.6072 - val_acc: 0.8500\n",
      "Epoch 230/600\n",
      "900/900 [==============================] - 1s 796us/step - loss: 0.3463 - acc: 0.8478 - val_loss: 0.5712 - val_acc: 0.8300\n",
      "Epoch 231/600\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.3395 - acc: 0.8567 - val_loss: 0.6008 - val_acc: 0.7900\n",
      "Epoch 232/600\n",
      "900/900 [==============================] - 1s 857us/step - loss: 0.3651 - acc: 0.8378 - val_loss: 0.5668 - val_acc: 0.7900\n",
      "Epoch 233/600\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.3506 - acc: 0.8456 - val_loss: 0.5728 - val_acc: 0.8000\n",
      "Epoch 234/600\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.3365 - acc: 0.8389 - val_loss: 0.5700 - val_acc: 0.7900\n",
      "Epoch 235/600\n",
      "900/900 [==============================] - 1s 809us/step - loss: 0.3388 - acc: 0.8489 - val_loss: 0.6103 - val_acc: 0.8000\n",
      "Epoch 236/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.3259 - acc: 0.8567 - val_loss: 0.5805 - val_acc: 0.7900\n",
      "Epoch 237/600\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.3385 - acc: 0.8456 - val_loss: 0.5592 - val_acc: 0.8000\n",
      "Epoch 238/600\n",
      "900/900 [==============================] - 1s 818us/step - loss: 0.3417 - acc: 0.8544 - val_loss: 0.6124 - val_acc: 0.7700\n",
      "Epoch 239/600\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.3284 - acc: 0.8644 - val_loss: 0.6047 - val_acc: 0.8100\n",
      "Epoch 240/600\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.3446 - acc: 0.8522 - val_loss: 0.6323 - val_acc: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.3269 - acc: 0.8644 - val_loss: 0.6379 - val_acc: 0.7800\n",
      "Epoch 242/600\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.3365 - acc: 0.8389 - val_loss: 0.6168 - val_acc: 0.8100\n",
      "Epoch 243/600\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.3260 - acc: 0.8467 - val_loss: 0.5953 - val_acc: 0.8000\n",
      "Epoch 244/600\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.3510 - acc: 0.8533 - val_loss: 0.5958 - val_acc: 0.7900\n",
      "Epoch 245/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.3201 - acc: 0.8567 - val_loss: 0.6290 - val_acc: 0.8100\n",
      "Epoch 246/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.3225 - acc: 0.8522 - val_loss: 0.5721 - val_acc: 0.8000\n",
      "Epoch 247/600\n",
      "900/900 [==============================] - 1s 698us/step - loss: 0.3332 - acc: 0.8444 - val_loss: 0.6195 - val_acc: 0.7900\n",
      "Epoch 248/600\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.3228 - acc: 0.8678 - val_loss: 0.6540 - val_acc: 0.7700\n",
      "Epoch 249/600\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.3460 - acc: 0.8511 - val_loss: 0.6691 - val_acc: 0.7900\n",
      "Epoch 250/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.3042 - acc: 0.8722 - val_loss: 0.6218 - val_acc: 0.7900\n",
      "Epoch 251/600\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.3358 - acc: 0.8411 - val_loss: 0.5956 - val_acc: 0.7800\n",
      "Epoch 252/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.3152 - acc: 0.8589 - val_loss: 0.5734 - val_acc: 0.8200\n",
      "Epoch 253/600\n",
      "900/900 [==============================] - 1s 699us/step - loss: 0.3407 - acc: 0.8533 - val_loss: 0.5862 - val_acc: 0.7900\n",
      "Epoch 254/600\n",
      "900/900 [==============================] - 1s 701us/step - loss: 0.3113 - acc: 0.8700 - val_loss: 0.6311 - val_acc: 0.7800\n",
      "Epoch 255/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.3360 - acc: 0.8600 - val_loss: 0.6368 - val_acc: 0.8200\n",
      "Epoch 256/600\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.3194 - acc: 0.8656 - val_loss: 0.5873 - val_acc: 0.7900\n",
      "Epoch 257/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.3131 - acc: 0.8644 - val_loss: 0.6263 - val_acc: 0.7800\n",
      "Epoch 258/600\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.2956 - acc: 0.8722 - val_loss: 0.6509 - val_acc: 0.7900\n",
      "Epoch 259/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.3263 - acc: 0.8589 - val_loss: 0.5761 - val_acc: 0.8000\n",
      "Epoch 260/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.2927 - acc: 0.8711 - val_loss: 0.6671 - val_acc: 0.8100\n",
      "Epoch 261/600\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.3015 - acc: 0.8767 - val_loss: 0.6402 - val_acc: 0.7900\n",
      "Epoch 262/600\n",
      "900/900 [==============================] - 1s 695us/step - loss: 0.2894 - acc: 0.8767 - val_loss: 0.5872 - val_acc: 0.8300\n",
      "Epoch 263/600\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.3027 - acc: 0.8700 - val_loss: 0.6887 - val_acc: 0.7800\n",
      "Epoch 264/600\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.3017 - acc: 0.8722 - val_loss: 0.6814 - val_acc: 0.8100\n",
      "Epoch 265/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.3174 - acc: 0.8478 - val_loss: 0.7311 - val_acc: 0.8100\n",
      "Epoch 266/600\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.3026 - acc: 0.8811 - val_loss: 0.6807 - val_acc: 0.7600\n",
      "Epoch 267/600\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.3286 - acc: 0.8544 - val_loss: 0.6371 - val_acc: 0.8000\n",
      "Epoch 268/600\n",
      "900/900 [==============================] - 1s 707us/step - loss: 0.3356 - acc: 0.8467 - val_loss: 0.6408 - val_acc: 0.8000\n",
      "Epoch 269/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.3198 - acc: 0.8711 - val_loss: 0.6635 - val_acc: 0.8000\n",
      "Epoch 270/600\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.2992 - acc: 0.8700 - val_loss: 0.6662 - val_acc: 0.7900\n",
      "Epoch 271/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.3145 - acc: 0.8789 - val_loss: 0.6516 - val_acc: 0.7900\n",
      "Epoch 272/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.2960 - acc: 0.8711 - val_loss: 0.6674 - val_acc: 0.7500\n",
      "Epoch 273/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.3026 - acc: 0.8678 - val_loss: 0.6858 - val_acc: 0.7900\n",
      "Epoch 274/600\n",
      "900/900 [==============================] - 1s 705us/step - loss: 0.3149 - acc: 0.8667 - val_loss: 0.6661 - val_acc: 0.8100\n",
      "Epoch 275/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.2893 - acc: 0.8678 - val_loss: 0.6642 - val_acc: 0.8100\n",
      "Epoch 276/600\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.3229 - acc: 0.8444 - val_loss: 0.6713 - val_acc: 0.8100\n",
      "Epoch 277/600\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.3021 - acc: 0.8667 - val_loss: 0.6479 - val_acc: 0.7800\n",
      "Epoch 278/600\n",
      "900/900 [==============================] - 1s 700us/step - loss: 0.2755 - acc: 0.8889 - val_loss: 0.7697 - val_acc: 0.7900\n",
      "Epoch 279/600\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.3052 - acc: 0.8667 - val_loss: 0.7377 - val_acc: 0.7900\n",
      "Epoch 280/600\n",
      "900/900 [==============================] - 1s 724us/step - loss: 0.2903 - acc: 0.8778 - val_loss: 0.6988 - val_acc: 0.7600\n",
      "Epoch 281/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.2977 - acc: 0.8767 - val_loss: 0.6815 - val_acc: 0.7800\n",
      "Epoch 282/600\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.3120 - acc: 0.8678 - val_loss: 0.6578 - val_acc: 0.7800\n",
      "Epoch 283/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.2863 - acc: 0.8767 - val_loss: 0.6363 - val_acc: 0.7700\n",
      "Epoch 284/600\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.2835 - acc: 0.8678 - val_loss: 0.6198 - val_acc: 0.8000\n",
      "Epoch 285/600\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.2905 - acc: 0.8633 - val_loss: 0.6606 - val_acc: 0.7900\n",
      "Epoch 286/600\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.2988 - acc: 0.8744 - val_loss: 0.7986 - val_acc: 0.7900\n",
      "Epoch 287/600\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.2802 - acc: 0.8767 - val_loss: 0.7684 - val_acc: 0.7400\n",
      "Epoch 288/600\n",
      "900/900 [==============================] - 1s 868us/step - loss: 0.3243 - acc: 0.8611 - val_loss: 0.6678 - val_acc: 0.7800\n",
      "Epoch 289/600\n",
      "900/900 [==============================] - 1s 659us/step - loss: 0.3049 - acc: 0.8711 - val_loss: 0.6921 - val_acc: 0.7800\n",
      "Epoch 290/600\n",
      "900/900 [==============================] - 1s 633us/step - loss: 0.2932 - acc: 0.8767 - val_loss: 0.6799 - val_acc: 0.8000\n",
      "Epoch 291/600\n",
      "900/900 [==============================] - 1s 692us/step - loss: 0.2940 - acc: 0.8622 - val_loss: 0.7417 - val_acc: 0.7500\n",
      "Epoch 292/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.2895 - acc: 0.8622 - val_loss: 0.7430 - val_acc: 0.8000\n",
      "Epoch 293/600\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.2719 - acc: 0.8833 - val_loss: 0.7690 - val_acc: 0.7500\n",
      "Epoch 294/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.2834 - acc: 0.8767 - val_loss: 0.7632 - val_acc: 0.7800\n",
      "Epoch 295/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.2887 - acc: 0.8778 - val_loss: 0.6887 - val_acc: 0.7900\n",
      "Epoch 296/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.2818 - acc: 0.8867 - val_loss: 0.8029 - val_acc: 0.8000\n",
      "Epoch 297/600\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.2772 - acc: 0.8844 - val_loss: 0.7274 - val_acc: 0.8000\n",
      "Epoch 298/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.2752 - acc: 0.8822 - val_loss: 0.7295 - val_acc: 0.8100\n",
      "Epoch 299/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.2940 - acc: 0.8833 - val_loss: 0.6833 - val_acc: 0.8200\n",
      "Epoch 300/600\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.2936 - acc: 0.8689 - val_loss: 0.6968 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/600\n",
      "900/900 [==============================] - 1s 699us/step - loss: 0.2716 - acc: 0.8911 - val_loss: 0.7192 - val_acc: 0.8100\n",
      "Epoch 302/600\n",
      "900/900 [==============================] - 1s 706us/step - loss: 0.2826 - acc: 0.8733 - val_loss: 0.7098 - val_acc: 0.8200\n",
      "Epoch 303/600\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.2705 - acc: 0.8867 - val_loss: 0.7048 - val_acc: 0.7900\n",
      "Epoch 304/600\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.2810 - acc: 0.8833 - val_loss: 0.7516 - val_acc: 0.7900\n",
      "Epoch 305/600\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.2760 - acc: 0.8922 - val_loss: 0.8098 - val_acc: 0.7900\n",
      "Epoch 306/600\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.2588 - acc: 0.8922 - val_loss: 0.7699 - val_acc: 0.8000\n",
      "Epoch 307/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.2855 - acc: 0.8622 - val_loss: 0.7445 - val_acc: 0.7900\n",
      "Epoch 308/600\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.2887 - acc: 0.8689 - val_loss: 0.7417 - val_acc: 0.7300\n",
      "Epoch 309/600\n",
      "900/900 [==============================] - 1s 716us/step - loss: 0.2805 - acc: 0.8744 - val_loss: 0.7065 - val_acc: 0.7700\n",
      "Epoch 310/600\n",
      "900/900 [==============================] - 1s 715us/step - loss: 0.2518 - acc: 0.8922 - val_loss: 0.7446 - val_acc: 0.7500\n",
      "Epoch 311/600\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.2697 - acc: 0.8789 - val_loss: 0.7595 - val_acc: 0.7600\n",
      "Epoch 312/600\n",
      "900/900 [==============================] - 1s 697us/step - loss: 0.2549 - acc: 0.8911 - val_loss: 0.7303 - val_acc: 0.8000\n",
      "Epoch 313/600\n",
      "900/900 [==============================] - 1s 706us/step - loss: 0.2587 - acc: 0.8922 - val_loss: 0.7216 - val_acc: 0.8000\n",
      "Epoch 314/600\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.2383 - acc: 0.9056 - val_loss: 0.7488 - val_acc: 0.8100\n",
      "Epoch 315/600\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.2776 - acc: 0.8767 - val_loss: 0.7898 - val_acc: 0.7700\n",
      "Epoch 316/600\n",
      "900/900 [==============================] - 1s 688us/step - loss: 0.2529 - acc: 0.8978 - val_loss: 0.7731 - val_acc: 0.7800\n",
      "Epoch 317/600\n",
      "900/900 [==============================] - 1s 690us/step - loss: 0.2647 - acc: 0.8800 - val_loss: 0.8592 - val_acc: 0.7900\n",
      "Epoch 318/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.2563 - acc: 0.8933 - val_loss: 0.7488 - val_acc: 0.7700\n",
      "Epoch 319/600\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.2584 - acc: 0.8944 - val_loss: 0.7362 - val_acc: 0.7700\n",
      "Epoch 320/600\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.2937 - acc: 0.8867 - val_loss: 0.7615 - val_acc: 0.8000\n",
      "Epoch 321/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.2683 - acc: 0.8800 - val_loss: 0.7615 - val_acc: 0.7900\n",
      "Epoch 322/600\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.2712 - acc: 0.8800 - val_loss: 0.7152 - val_acc: 0.7900\n",
      "Epoch 323/600\n",
      "900/900 [==============================] - 1s 713us/step - loss: 0.2599 - acc: 0.8922 - val_loss: 0.7544 - val_acc: 0.8200\n",
      "Epoch 324/600\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.2576 - acc: 0.8878 - val_loss: 0.7747 - val_acc: 0.7900\n",
      "Epoch 325/600\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.2462 - acc: 0.8944 - val_loss: 0.7641 - val_acc: 0.7900\n",
      "Epoch 326/600\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.2447 - acc: 0.8867 - val_loss: 0.7896 - val_acc: 0.7700\n",
      "Epoch 327/600\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.2706 - acc: 0.8800 - val_loss: 0.7257 - val_acc: 0.7800\n",
      "Epoch 328/600\n",
      "900/900 [==============================] - 1s 774us/step - loss: 0.2417 - acc: 0.8844 - val_loss: 0.7716 - val_acc: 0.7700\n",
      "Epoch 329/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.2590 - acc: 0.8922 - val_loss: 0.8021 - val_acc: 0.7900\n",
      "Epoch 330/600\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.2611 - acc: 0.8933 - val_loss: 0.7943 - val_acc: 0.8100\n",
      "Epoch 331/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.2412 - acc: 0.8922 - val_loss: 0.7156 - val_acc: 0.7800\n",
      "Epoch 332/600\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.2629 - acc: 0.8978 - val_loss: 0.6965 - val_acc: 0.8100\n",
      "Epoch 333/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.2654 - acc: 0.8900 - val_loss: 0.7320 - val_acc: 0.7500\n",
      "Epoch 334/600\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.2608 - acc: 0.8889 - val_loss: 0.7555 - val_acc: 0.7500\n",
      "Epoch 335/600\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.2606 - acc: 0.8822 - val_loss: 0.7582 - val_acc: 0.7900\n",
      "Epoch 336/600\n",
      "900/900 [==============================] - 1s 726us/step - loss: 0.2798 - acc: 0.8922 - val_loss: 0.7400 - val_acc: 0.7700\n",
      "Epoch 337/600\n",
      "900/900 [==============================] - 1s 703us/step - loss: 0.2523 - acc: 0.8822 - val_loss: 0.6802 - val_acc: 0.8300\n",
      "Epoch 338/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.2460 - acc: 0.8922 - val_loss: 0.7683 - val_acc: 0.7800\n",
      "Epoch 339/600\n",
      "900/900 [==============================] - 1s 717us/step - loss: 0.2464 - acc: 0.8978 - val_loss: 0.7152 - val_acc: 0.8000\n",
      "Epoch 340/600\n",
      "900/900 [==============================] - 1s 716us/step - loss: 0.2621 - acc: 0.8900 - val_loss: 0.7487 - val_acc: 0.8000\n",
      "Epoch 341/600\n",
      "900/900 [==============================] - 1s 710us/step - loss: 0.2540 - acc: 0.8889 - val_loss: 0.7144 - val_acc: 0.8100\n",
      "Epoch 342/600\n",
      "900/900 [==============================] - 1s 714us/step - loss: 0.2653 - acc: 0.8922 - val_loss: 0.7459 - val_acc: 0.8100\n",
      "Epoch 343/600\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.2435 - acc: 0.8989 - val_loss: 0.8501 - val_acc: 0.8000\n",
      "Epoch 344/600\n",
      "900/900 [==============================] - 1s 703us/step - loss: 0.2545 - acc: 0.8844 - val_loss: 0.7571 - val_acc: 0.7800\n",
      "Epoch 345/600\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.2551 - acc: 0.8989 - val_loss: 0.7796 - val_acc: 0.7800\n",
      "Epoch 346/600\n",
      "900/900 [==============================] - 1s 662us/step - loss: 0.2500 - acc: 0.8911 - val_loss: 0.7843 - val_acc: 0.7700\n",
      "Epoch 347/600\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.2425 - acc: 0.8944 - val_loss: 0.8265 - val_acc: 0.7800\n",
      "Epoch 348/600\n",
      "900/900 [==============================] - 1s 796us/step - loss: 0.2234 - acc: 0.9044 - val_loss: 0.9009 - val_acc: 0.7600\n",
      "Epoch 349/600\n",
      "900/900 [==============================] - 1s 806us/step - loss: 0.2869 - acc: 0.8811 - val_loss: 0.8127 - val_acc: 0.7500\n",
      "Epoch 350/600\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.2636 - acc: 0.8956 - val_loss: 0.7644 - val_acc: 0.7800\n",
      "Epoch 351/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.2155 - acc: 0.9122 - val_loss: 0.8396 - val_acc: 0.7700\n",
      "Epoch 352/600\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.2294 - acc: 0.9067 - val_loss: 0.8524 - val_acc: 0.8000\n",
      "Epoch 353/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.2356 - acc: 0.8967 - val_loss: 0.7990 - val_acc: 0.7900\n",
      "Epoch 354/600\n",
      "900/900 [==============================] - 1s 719us/step - loss: 0.2608 - acc: 0.8889 - val_loss: 0.7336 - val_acc: 0.7800\n",
      "Epoch 355/600\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.2158 - acc: 0.9122 - val_loss: 0.8462 - val_acc: 0.8100\n",
      "Epoch 356/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.2639 - acc: 0.8911 - val_loss: 0.7791 - val_acc: 0.7500\n",
      "Epoch 357/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.2541 - acc: 0.8956 - val_loss: 0.8211 - val_acc: 0.7400\n",
      "Epoch 358/600\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.2321 - acc: 0.9078 - val_loss: 0.7757 - val_acc: 0.7700\n",
      "Epoch 359/600\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.2396 - acc: 0.8956 - val_loss: 0.8352 - val_acc: 0.8000\n",
      "Epoch 360/600\n",
      "900/900 [==============================] - 1s 716us/step - loss: 0.2637 - acc: 0.8978 - val_loss: 0.7158 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/600\n",
      "900/900 [==============================] - 1s 561us/step - loss: 0.2502 - acc: 0.8944 - val_loss: 0.7395 - val_acc: 0.8000\n",
      "Epoch 362/600\n",
      "900/900 [==============================] - 1s 625us/step - loss: 0.2160 - acc: 0.9111 - val_loss: 0.7435 - val_acc: 0.8300\n",
      "Epoch 363/600\n",
      "900/900 [==============================] - 1s 676us/step - loss: 0.2211 - acc: 0.9044 - val_loss: 0.8075 - val_acc: 0.7900\n",
      "Epoch 364/600\n",
      "900/900 [==============================] - 1s 666us/step - loss: 0.2465 - acc: 0.9056 - val_loss: 0.7849 - val_acc: 0.7800\n",
      "Epoch 365/600\n",
      "900/900 [==============================] - 1s 687us/step - loss: 0.2289 - acc: 0.9111 - val_loss: 0.8232 - val_acc: 0.7800\n",
      "Epoch 366/600\n",
      "900/900 [==============================] - 1s 688us/step - loss: 0.2353 - acc: 0.9022 - val_loss: 0.8352 - val_acc: 0.7900\n",
      "Epoch 367/600\n",
      "900/900 [==============================] - 1s 703us/step - loss: 0.2208 - acc: 0.9144 - val_loss: 0.8501 - val_acc: 0.8200\n",
      "Epoch 368/600\n",
      "900/900 [==============================] - 1s 700us/step - loss: 0.2186 - acc: 0.9089 - val_loss: 0.8302 - val_acc: 0.7900\n",
      "Epoch 369/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.2312 - acc: 0.8978 - val_loss: 0.8086 - val_acc: 0.7900\n",
      "Epoch 370/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.2437 - acc: 0.9100 - val_loss: 0.9111 - val_acc: 0.8100\n",
      "Epoch 371/600\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.2154 - acc: 0.9144 - val_loss: 0.8687 - val_acc: 0.7700\n",
      "Epoch 372/600\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.2191 - acc: 0.9100 - val_loss: 0.8530 - val_acc: 0.7900\n",
      "Epoch 373/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.2474 - acc: 0.9033 - val_loss: 0.8669 - val_acc: 0.8000\n",
      "Epoch 374/600\n",
      "900/900 [==============================] - 1s 716us/step - loss: 0.2215 - acc: 0.9089 - val_loss: 0.8809 - val_acc: 0.8000\n",
      "Epoch 375/600\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.2591 - acc: 0.8933 - val_loss: 0.8423 - val_acc: 0.7500\n",
      "Epoch 376/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.2140 - acc: 0.9122 - val_loss: 0.8566 - val_acc: 0.7800\n",
      "Epoch 377/600\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.2263 - acc: 0.9022 - val_loss: 0.8216 - val_acc: 0.7700\n",
      "Epoch 378/600\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.2428 - acc: 0.9056 - val_loss: 0.7898 - val_acc: 0.7900\n",
      "Epoch 379/600\n",
      "900/900 [==============================] - 1s 695us/step - loss: 0.2262 - acc: 0.9089 - val_loss: 0.7781 - val_acc: 0.8100\n",
      "Epoch 380/600\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.2284 - acc: 0.9000 - val_loss: 0.7622 - val_acc: 0.8100\n",
      "Epoch 381/600\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.2352 - acc: 0.9111 - val_loss: 0.8054 - val_acc: 0.8000\n",
      "Epoch 382/600\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.2383 - acc: 0.8933 - val_loss: 0.7038 - val_acc: 0.7900\n",
      "Epoch 383/600\n",
      "900/900 [==============================] - 1s 719us/step - loss: 0.2239 - acc: 0.9133 - val_loss: 0.9253 - val_acc: 0.7800\n",
      "Epoch 384/600\n",
      "900/900 [==============================] - 1s 796us/step - loss: 0.2136 - acc: 0.9100 - val_loss: 0.8133 - val_acc: 0.7800\n",
      "Epoch 385/600\n",
      "900/900 [==============================] - 1s 799us/step - loss: 0.2392 - acc: 0.9000 - val_loss: 0.7986 - val_acc: 0.8000\n",
      "Epoch 386/600\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.2256 - acc: 0.9044 - val_loss: 0.8689 - val_acc: 0.7800\n",
      "Epoch 387/600\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.2273 - acc: 0.8878 - val_loss: 0.7447 - val_acc: 0.7900\n",
      "Epoch 388/600\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.2182 - acc: 0.9144 - val_loss: 1.0229 - val_acc: 0.7900\n",
      "Epoch 389/600\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.2031 - acc: 0.9156 - val_loss: 0.8459 - val_acc: 0.7700\n",
      "Epoch 390/600\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.2232 - acc: 0.9067 - val_loss: 0.8635 - val_acc: 0.8000\n",
      "Epoch 391/600\n",
      "900/900 [==============================] - 1s 708us/step - loss: 0.2282 - acc: 0.8978 - val_loss: 0.8901 - val_acc: 0.7600\n",
      "Epoch 392/600\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.2384 - acc: 0.9067 - val_loss: 0.8426 - val_acc: 0.7900\n",
      "Epoch 393/600\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.2344 - acc: 0.8933 - val_loss: 0.8151 - val_acc: 0.8000\n",
      "Epoch 394/600\n",
      "900/900 [==============================] - 1s 705us/step - loss: 0.2326 - acc: 0.8989 - val_loss: 0.7314 - val_acc: 0.8100\n",
      "Epoch 395/600\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.2295 - acc: 0.9122 - val_loss: 0.8229 - val_acc: 0.8000\n",
      "Epoch 396/600\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.2178 - acc: 0.9133 - val_loss: 0.8346 - val_acc: 0.8100\n",
      "Epoch 397/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.2183 - acc: 0.9122 - val_loss: 0.7737 - val_acc: 0.8100\n",
      "Epoch 398/600\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.1931 - acc: 0.9311 - val_loss: 1.0454 - val_acc: 0.7800\n",
      "Epoch 399/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.2388 - acc: 0.9044 - val_loss: 0.9036 - val_acc: 0.7600\n",
      "Epoch 400/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.2069 - acc: 0.9222 - val_loss: 0.8409 - val_acc: 0.7600\n",
      "Epoch 401/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.2138 - acc: 0.9122 - val_loss: 0.8980 - val_acc: 0.7900\n",
      "Epoch 402/600\n",
      "900/900 [==============================] - 1s 743us/step - loss: 0.2151 - acc: 0.9056 - val_loss: 0.9360 - val_acc: 0.7700\n",
      "Epoch 403/600\n",
      "900/900 [==============================] - 1s 726us/step - loss: 0.2132 - acc: 0.9078 - val_loss: 0.8226 - val_acc: 0.7700\n",
      "Epoch 404/600\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.2027 - acc: 0.9167 - val_loss: 0.9321 - val_acc: 0.7900\n",
      "Epoch 405/600\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.1861 - acc: 0.9244 - val_loss: 0.9932 - val_acc: 0.7900\n",
      "Epoch 406/600\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.2070 - acc: 0.9100 - val_loss: 0.9853 - val_acc: 0.7700\n",
      "Epoch 407/600\n",
      "900/900 [==============================] - 1s 714us/step - loss: 0.2120 - acc: 0.9233 - val_loss: 0.9215 - val_acc: 0.7600\n",
      "Epoch 408/600\n",
      "900/900 [==============================] - 1s 719us/step - loss: 0.2058 - acc: 0.9156 - val_loss: 0.8336 - val_acc: 0.7800\n",
      "Epoch 409/600\n",
      "900/900 [==============================] - 1s 813us/step - loss: 0.2149 - acc: 0.9144 - val_loss: 0.8402 - val_acc: 0.7800\n",
      "Epoch 410/600\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.2133 - acc: 0.9011 - val_loss: 0.8891 - val_acc: 0.7800\n",
      "Epoch 411/600\n",
      "900/900 [==============================] - 1s 862us/step - loss: 0.2048 - acc: 0.9156 - val_loss: 1.0920 - val_acc: 0.7900\n",
      "Epoch 412/600\n",
      "900/900 [==============================] - 1s 857us/step - loss: 0.2208 - acc: 0.9100 - val_loss: 0.8708 - val_acc: 0.7500\n",
      "Epoch 413/600\n",
      "900/900 [==============================] - 0s 526us/step - loss: 0.1934 - acc: 0.9178 - val_loss: 0.9284 - val_acc: 0.7800\n",
      "Epoch 414/600\n",
      "900/900 [==============================] - 1s 602us/step - loss: 0.2093 - acc: 0.9178 - val_loss: 0.9013 - val_acc: 0.7700\n",
      "Epoch 415/600\n",
      "900/900 [==============================] - 1s 600us/step - loss: 0.1950 - acc: 0.9144 - val_loss: 1.0267 - val_acc: 0.7800\n",
      "Epoch 416/600\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.1997 - acc: 0.9189 - val_loss: 0.9618 - val_acc: 0.7900\n",
      "Epoch 417/600\n",
      "900/900 [==============================] - 1s 846us/step - loss: 0.2011 - acc: 0.9167 - val_loss: 0.8331 - val_acc: 0.7900\n",
      "Epoch 418/600\n",
      "900/900 [==============================] - 1s 838us/step - loss: 0.2053 - acc: 0.9189 - val_loss: 0.9844 - val_acc: 0.8100\n",
      "Epoch 419/600\n",
      "900/900 [==============================] - 1s 808us/step - loss: 0.2096 - acc: 0.9178 - val_loss: 0.9910 - val_acc: 0.7900\n",
      "Epoch 420/600\n",
      "900/900 [==============================] - 1s 845us/step - loss: 0.2126 - acc: 0.9078 - val_loss: 0.9135 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/600\n",
      "900/900 [==============================] - 1s 860us/step - loss: 0.2145 - acc: 0.9156 - val_loss: 0.8515 - val_acc: 0.8000\n",
      "Epoch 422/600\n",
      "900/900 [==============================] - 1s 824us/step - loss: 0.1906 - acc: 0.9211 - val_loss: 0.9274 - val_acc: 0.8000\n",
      "Epoch 423/600\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.1861 - acc: 0.9178 - val_loss: 0.9521 - val_acc: 0.8000\n",
      "Epoch 424/600\n",
      "900/900 [==============================] - 1s 830us/step - loss: 0.1812 - acc: 0.9222 - val_loss: 1.0265 - val_acc: 0.7900\n",
      "Epoch 425/600\n",
      "900/900 [==============================] - 1s 572us/step - loss: 0.2134 - acc: 0.9189 - val_loss: 0.9131 - val_acc: 0.7700\n",
      "Epoch 426/600\n",
      "900/900 [==============================] - 1s 633us/step - loss: 0.1999 - acc: 0.9178 - val_loss: 1.0539 - val_acc: 0.7500\n",
      "Epoch 427/600\n",
      "900/900 [==============================] - 1s 701us/step - loss: 0.2073 - acc: 0.9089 - val_loss: 0.9256 - val_acc: 0.8000\n",
      "Epoch 428/600\n",
      "900/900 [==============================] - 1s 597us/step - loss: 0.1873 - acc: 0.9178 - val_loss: 0.9894 - val_acc: 0.7900\n",
      "Epoch 429/600\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.2057 - acc: 0.9200 - val_loss: 0.9106 - val_acc: 0.7600\n",
      "Epoch 430/600\n",
      "900/900 [==============================] - 1s 686us/step - loss: 0.1964 - acc: 0.9222 - val_loss: 0.9286 - val_acc: 0.8000\n",
      "Epoch 431/600\n",
      "900/900 [==============================] - 1s 634us/step - loss: 0.1789 - acc: 0.9322 - val_loss: 1.0123 - val_acc: 0.7600\n",
      "Epoch 432/600\n",
      "900/900 [==============================] - 0s 375us/step - loss: 0.2032 - acc: 0.9122 - val_loss: 0.9845 - val_acc: 0.8000\n",
      "Epoch 433/600\n",
      "900/900 [==============================] - 0s 339us/step - loss: 0.2005 - acc: 0.9100 - val_loss: 0.9271 - val_acc: 0.7700\n",
      "Epoch 434/600\n",
      "900/900 [==============================] - 0s 377us/step - loss: 0.1795 - acc: 0.9356 - val_loss: 0.9849 - val_acc: 0.8100\n",
      "Epoch 435/600\n",
      "900/900 [==============================] - 0s 340us/step - loss: 0.1794 - acc: 0.9300 - val_loss: 0.9153 - val_acc: 0.8000\n",
      "Epoch 436/600\n",
      "900/900 [==============================] - 0s 403us/step - loss: 0.1914 - acc: 0.9178 - val_loss: 1.0853 - val_acc: 0.7700\n",
      "Epoch 437/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.1961 - acc: 0.9233 - val_loss: 0.9107 - val_acc: 0.7900\n",
      "Epoch 438/600\n",
      "900/900 [==============================] - 1s 690us/step - loss: 0.2351 - acc: 0.8989 - val_loss: 0.8432 - val_acc: 0.7800\n",
      "Epoch 439/600\n",
      "900/900 [==============================] - 1s 677us/step - loss: 0.1982 - acc: 0.9233 - val_loss: 1.0153 - val_acc: 0.7800\n",
      "Epoch 440/600\n",
      "900/900 [==============================] - 1s 664us/step - loss: 0.1947 - acc: 0.9322 - val_loss: 1.1145 - val_acc: 0.8000\n",
      "Epoch 441/600\n",
      "900/900 [==============================] - 1s 630us/step - loss: 0.1807 - acc: 0.9378 - val_loss: 1.0319 - val_acc: 0.7900\n",
      "Epoch 442/600\n",
      "900/900 [==============================] - 1s 708us/step - loss: 0.1718 - acc: 0.9322 - val_loss: 1.0711 - val_acc: 0.7700\n",
      "Epoch 443/600\n",
      "900/900 [==============================] - 1s 663us/step - loss: 0.1767 - acc: 0.9311 - val_loss: 1.0957 - val_acc: 0.7700\n",
      "Epoch 444/600\n",
      "900/900 [==============================] - 1s 674us/step - loss: 0.2154 - acc: 0.9100 - val_loss: 1.0570 - val_acc: 0.8000\n",
      "Epoch 445/600\n",
      "900/900 [==============================] - 1s 705us/step - loss: 0.1801 - acc: 0.9300 - val_loss: 1.1393 - val_acc: 0.7800\n",
      "Epoch 446/600\n",
      "900/900 [==============================] - 1s 699us/step - loss: 0.1742 - acc: 0.9278 - val_loss: 0.9645 - val_acc: 0.7600\n",
      "Epoch 447/600\n",
      "900/900 [==============================] - 1s 678us/step - loss: 0.1899 - acc: 0.9233 - val_loss: 0.9695 - val_acc: 0.7700\n",
      "Epoch 448/600\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.1845 - acc: 0.9333 - val_loss: 1.1538 - val_acc: 0.7900\n",
      "Epoch 449/600\n",
      "900/900 [==============================] - 1s 686us/step - loss: 0.2003 - acc: 0.9133 - val_loss: 1.0881 - val_acc: 0.7800\n",
      "Epoch 450/600\n",
      "900/900 [==============================] - 1s 686us/step - loss: 0.1878 - acc: 0.9256 - val_loss: 1.0743 - val_acc: 0.7900\n",
      "Epoch 451/600\n",
      "900/900 [==============================] - 1s 679us/step - loss: 0.1971 - acc: 0.9156 - val_loss: 1.1419 - val_acc: 0.7800\n",
      "Epoch 452/600\n",
      "900/900 [==============================] - 1s 682us/step - loss: 0.1930 - acc: 0.9322 - val_loss: 1.1682 - val_acc: 0.7900\n",
      "Epoch 453/600\n",
      "900/900 [==============================] - 1s 664us/step - loss: 0.1867 - acc: 0.9200 - val_loss: 1.3369 - val_acc: 0.8100\n",
      "Epoch 454/600\n",
      "900/900 [==============================] - 1s 669us/step - loss: 0.2182 - acc: 0.9111 - val_loss: 0.9830 - val_acc: 0.8000\n",
      "Epoch 455/600\n",
      "900/900 [==============================] - 1s 675us/step - loss: 0.1603 - acc: 0.9378 - val_loss: 0.9290 - val_acc: 0.7700\n",
      "Epoch 456/600\n",
      "900/900 [==============================] - 1s 609us/step - loss: 0.1980 - acc: 0.9189 - val_loss: 1.0521 - val_acc: 0.7700\n",
      "Epoch 457/600\n",
      "900/900 [==============================] - 1s 668us/step - loss: 0.1796 - acc: 0.9300 - val_loss: 1.0300 - val_acc: 0.7800\n",
      "Epoch 458/600\n",
      "900/900 [==============================] - 1s 671us/step - loss: 0.1948 - acc: 0.9189 - val_loss: 1.0521 - val_acc: 0.7800\n",
      "Epoch 459/600\n",
      "900/900 [==============================] - 1s 658us/step - loss: 0.1564 - acc: 0.9378 - val_loss: 1.1072 - val_acc: 0.7800\n",
      "Epoch 460/600\n",
      "900/900 [==============================] - 1s 608us/step - loss: 0.1864 - acc: 0.9300 - val_loss: 1.0247 - val_acc: 0.7800\n",
      "Epoch 461/600\n",
      "900/900 [==============================] - 1s 626us/step - loss: 0.1892 - acc: 0.9244 - val_loss: 1.0130 - val_acc: 0.7900\n",
      "Epoch 462/600\n",
      "900/900 [==============================] - 1s 612us/step - loss: 0.1757 - acc: 0.9244 - val_loss: 0.9701 - val_acc: 0.7800\n",
      "Epoch 463/600\n",
      "900/900 [==============================] - 1s 613us/step - loss: 0.1694 - acc: 0.9322 - val_loss: 1.1084 - val_acc: 0.7700\n",
      "Epoch 464/600\n",
      "900/900 [==============================] - 1s 613us/step - loss: 0.1700 - acc: 0.9422 - val_loss: 1.0352 - val_acc: 0.8000\n",
      "Epoch 465/600\n",
      "900/900 [==============================] - 1s 563us/step - loss: 0.1825 - acc: 0.9278 - val_loss: 1.0173 - val_acc: 0.8100\n",
      "Epoch 466/600\n",
      "900/900 [==============================] - 1s 565us/step - loss: 0.1813 - acc: 0.9356 - val_loss: 0.9965 - val_acc: 0.8100\n",
      "Epoch 467/600\n",
      "900/900 [==============================] - 1s 564us/step - loss: 0.1882 - acc: 0.9378 - val_loss: 1.0355 - val_acc: 0.8100\n",
      "Epoch 468/600\n",
      "900/900 [==============================] - 1s 561us/step - loss: 0.1742 - acc: 0.9311 - val_loss: 1.1375 - val_acc: 0.7900\n",
      "Epoch 469/600\n",
      "900/900 [==============================] - 1s 560us/step - loss: 0.1886 - acc: 0.9278 - val_loss: 1.0806 - val_acc: 0.7800\n",
      "Epoch 470/600\n",
      "900/900 [==============================] - 1s 591us/step - loss: 0.1572 - acc: 0.9356 - val_loss: 0.9976 - val_acc: 0.7800\n",
      "Epoch 471/600\n",
      "900/900 [==============================] - 1s 628us/step - loss: 0.1898 - acc: 0.9267 - val_loss: 0.9529 - val_acc: 0.7800\n",
      "Epoch 472/600\n",
      "900/900 [==============================] - 1s 626us/step - loss: 0.1883 - acc: 0.9289 - val_loss: 1.0204 - val_acc: 0.7800\n",
      "Epoch 473/600\n",
      "900/900 [==============================] - 1s 607us/step - loss: 0.1503 - acc: 0.9400 - val_loss: 1.2345 - val_acc: 0.7800\n",
      "Epoch 474/600\n",
      "900/900 [==============================] - 1s 602us/step - loss: 0.1728 - acc: 0.9333 - val_loss: 1.1038 - val_acc: 0.7800\n",
      "Epoch 475/600\n",
      "900/900 [==============================] - 1s 604us/step - loss: 0.1705 - acc: 0.9256 - val_loss: 1.0392 - val_acc: 0.7900\n",
      "Epoch 476/600\n",
      "900/900 [==============================] - 1s 640us/step - loss: 0.1662 - acc: 0.9278 - val_loss: 1.0778 - val_acc: 0.7800\n",
      "Epoch 477/600\n",
      "900/900 [==============================] - 1s 659us/step - loss: 0.1719 - acc: 0.9244 - val_loss: 1.0221 - val_acc: 0.8000\n",
      "Epoch 478/600\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.1972 - acc: 0.9189 - val_loss: 1.0060 - val_acc: 0.7700\n",
      "Epoch 479/600\n",
      "900/900 [==============================] - 1s 700us/step - loss: 0.1746 - acc: 0.9300 - val_loss: 1.0445 - val_acc: 0.8200\n",
      "Epoch 480/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.1916 - acc: 0.9178 - val_loss: 1.0504 - val_acc: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/600\n",
      "900/900 [==============================] - 1s 681us/step - loss: 0.1637 - acc: 0.9322 - val_loss: 1.0709 - val_acc: 0.7900\n",
      "Epoch 482/600\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.1586 - acc: 0.9322 - val_loss: 1.1511 - val_acc: 0.7700\n",
      "Epoch 483/600\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.1833 - acc: 0.9244 - val_loss: 1.1191 - val_acc: 0.7800\n",
      "Epoch 484/600\n",
      "900/900 [==============================] - 1s 675us/step - loss: 0.1648 - acc: 0.9356 - val_loss: 0.9853 - val_acc: 0.8000\n",
      "Epoch 485/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.1896 - acc: 0.9189 - val_loss: 1.0265 - val_acc: 0.7900\n",
      "Epoch 486/600\n",
      "900/900 [==============================] - 1s 688us/step - loss: 0.1664 - acc: 0.9333 - val_loss: 1.0791 - val_acc: 0.7800\n",
      "Epoch 487/600\n",
      "900/900 [==============================] - 1s 671us/step - loss: 0.1602 - acc: 0.9244 - val_loss: 1.3565 - val_acc: 0.7800\n",
      "Epoch 488/600\n",
      "900/900 [==============================] - 1s 658us/step - loss: 0.1749 - acc: 0.9189 - val_loss: 1.0971 - val_acc: 0.7900\n",
      "Epoch 489/600\n",
      "900/900 [==============================] - 1s 689us/step - loss: 0.1888 - acc: 0.9222 - val_loss: 1.0223 - val_acc: 0.7700\n",
      "Epoch 490/600\n",
      "900/900 [==============================] - 1s 701us/step - loss: 0.1646 - acc: 0.9344 - val_loss: 1.0216 - val_acc: 0.7900\n",
      "Epoch 491/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.1628 - acc: 0.9311 - val_loss: 1.2225 - val_acc: 0.7900\n",
      "Epoch 492/600\n",
      "900/900 [==============================] - 1s 661us/step - loss: 0.1843 - acc: 0.9256 - val_loss: 1.0044 - val_acc: 0.7800\n",
      "Epoch 493/600\n",
      "900/900 [==============================] - 1s 685us/step - loss: 0.1668 - acc: 0.9333 - val_loss: 1.1081 - val_acc: 0.7900\n",
      "Epoch 494/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.1817 - acc: 0.9200 - val_loss: 1.0835 - val_acc: 0.7800\n",
      "Epoch 495/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.1368 - acc: 0.9378 - val_loss: 1.3265 - val_acc: 0.7500\n",
      "Epoch 496/600\n",
      "900/900 [==============================] - 1s 672us/step - loss: 0.1740 - acc: 0.9344 - val_loss: 1.1736 - val_acc: 0.7900\n",
      "Epoch 497/600\n",
      "900/900 [==============================] - 1s 672us/step - loss: 0.1733 - acc: 0.9300 - val_loss: 1.0737 - val_acc: 0.7800\n",
      "Epoch 498/600\n",
      "900/900 [==============================] - 1s 622us/step - loss: 0.1640 - acc: 0.9267 - val_loss: 1.0072 - val_acc: 0.8000\n",
      "Epoch 499/600\n",
      "900/900 [==============================] - 0s 530us/step - loss: 0.1670 - acc: 0.9367 - val_loss: 1.1670 - val_acc: 0.8000\n",
      "Epoch 500/600\n",
      "900/900 [==============================] - 1s 563us/step - loss: 0.1705 - acc: 0.9322 - val_loss: 1.1025 - val_acc: 0.8000\n",
      "Epoch 501/600\n",
      "900/900 [==============================] - 0s 531us/step - loss: 0.1754 - acc: 0.9267 - val_loss: 1.2151 - val_acc: 0.7700\n",
      "Epoch 502/600\n",
      "900/900 [==============================] - 1s 564us/step - loss: 0.1762 - acc: 0.9322 - val_loss: 1.1086 - val_acc: 0.7800\n",
      "Epoch 503/600\n",
      "900/900 [==============================] - 1s 572us/step - loss: 0.1764 - acc: 0.9233 - val_loss: 0.9986 - val_acc: 0.8200\n",
      "Epoch 504/600\n",
      "900/900 [==============================] - 1s 616us/step - loss: 0.1641 - acc: 0.9378 - val_loss: 1.0865 - val_acc: 0.7900\n",
      "Epoch 505/600\n",
      "900/900 [==============================] - 1s 584us/step - loss: 0.1588 - acc: 0.9356 - val_loss: 1.1209 - val_acc: 0.7700\n",
      "Epoch 506/600\n",
      "900/900 [==============================] - 1s 557us/step - loss: 0.1661 - acc: 0.9267 - val_loss: 1.1684 - val_acc: 0.7800\n",
      "Epoch 507/600\n",
      "900/900 [==============================] - 1s 561us/step - loss: 0.1815 - acc: 0.9300 - val_loss: 1.0358 - val_acc: 0.8000\n",
      "Epoch 508/600\n",
      "900/900 [==============================] - 1s 562us/step - loss: 0.1671 - acc: 0.9311 - val_loss: 1.0104 - val_acc: 0.7900\n",
      "Epoch 509/600\n",
      "900/900 [==============================] - 1s 563us/step - loss: 0.1521 - acc: 0.9411 - val_loss: 1.1394 - val_acc: 0.7800\n",
      "Epoch 510/600\n",
      "900/900 [==============================] - 1s 568us/step - loss: 0.1946 - acc: 0.9200 - val_loss: 1.0261 - val_acc: 0.7800\n",
      "Epoch 511/600\n",
      "900/900 [==============================] - 0s 555us/step - loss: 0.1568 - acc: 0.9367 - val_loss: 1.0054 - val_acc: 0.7800\n",
      "Epoch 512/600\n",
      "900/900 [==============================] - 1s 572us/step - loss: 0.1667 - acc: 0.9278 - val_loss: 1.2423 - val_acc: 0.7900\n",
      "Epoch 513/600\n",
      "900/900 [==============================] - 1s 565us/step - loss: 0.1395 - acc: 0.9422 - val_loss: 1.2410 - val_acc: 0.7900\n",
      "Epoch 514/600\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.1674 - acc: 0.9322 - val_loss: 1.1336 - val_acc: 0.7900\n",
      "Epoch 515/600\n",
      "900/900 [==============================] - 1s 598us/step - loss: 0.1677 - acc: 0.9411 - val_loss: 1.2223 - val_acc: 0.7900\n",
      "Epoch 516/600\n",
      "900/900 [==============================] - 1s 627us/step - loss: 0.1665 - acc: 0.9278 - val_loss: 1.0451 - val_acc: 0.7800\n",
      "Epoch 517/600\n",
      "900/900 [==============================] - 1s 743us/step - loss: 0.1663 - acc: 0.9333 - val_loss: 1.0082 - val_acc: 0.7800\n",
      "Epoch 518/600\n",
      "900/900 [==============================] - 1s 712us/step - loss: 0.1416 - acc: 0.9444 - val_loss: 1.0659 - val_acc: 0.7800\n",
      "Epoch 519/600\n",
      "900/900 [==============================] - 1s 714us/step - loss: 0.1721 - acc: 0.9322 - val_loss: 1.0784 - val_acc: 0.8000\n",
      "Epoch 520/600\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.1716 - acc: 0.9344 - val_loss: 1.2046 - val_acc: 0.8000\n",
      "Epoch 521/600\n",
      "900/900 [==============================] - 1s 875us/step - loss: 0.1389 - acc: 0.9411 - val_loss: 1.2425 - val_acc: 0.8000\n",
      "Epoch 522/600\n",
      "900/900 [==============================] - 1s 808us/step - loss: 0.1696 - acc: 0.9444 - val_loss: 1.2207 - val_acc: 0.7900\n",
      "Epoch 523/600\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.1595 - acc: 0.9389 - val_loss: 1.1650 - val_acc: 0.8000\n",
      "Epoch 524/600\n",
      "900/900 [==============================] - 1s 711us/step - loss: 0.1453 - acc: 0.9411 - val_loss: 1.1998 - val_acc: 0.7900\n",
      "Epoch 525/600\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.1693 - acc: 0.9333 - val_loss: 1.1341 - val_acc: 0.7800\n",
      "Epoch 526/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.1780 - acc: 0.9322 - val_loss: 1.0352 - val_acc: 0.7900\n",
      "Epoch 527/600\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.1596 - acc: 0.9356 - val_loss: 1.0917 - val_acc: 0.8000\n",
      "Epoch 528/600\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.1464 - acc: 0.9467 - val_loss: 0.9805 - val_acc: 0.7900\n",
      "Epoch 529/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.1435 - acc: 0.9444 - val_loss: 1.1742 - val_acc: 0.7800\n",
      "Epoch 530/600\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.1657 - acc: 0.9400 - val_loss: 1.0936 - val_acc: 0.8100\n",
      "Epoch 531/600\n",
      "900/900 [==============================] - 1s 722us/step - loss: 0.1561 - acc: 0.9356 - val_loss: 1.2221 - val_acc: 0.7900\n",
      "Epoch 532/600\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.1454 - acc: 0.9333 - val_loss: 1.1107 - val_acc: 0.8000\n",
      "Epoch 533/600\n",
      "900/900 [==============================] - 1s 707us/step - loss: 0.1692 - acc: 0.9289 - val_loss: 1.1345 - val_acc: 0.8000\n",
      "Epoch 534/600\n",
      "900/900 [==============================] - 1s 720us/step - loss: 0.1412 - acc: 0.9544 - val_loss: 1.2644 - val_acc: 0.7800\n",
      "Epoch 535/600\n",
      "900/900 [==============================] - 1s 726us/step - loss: 0.1387 - acc: 0.9456 - val_loss: 1.0696 - val_acc: 0.7900\n",
      "Epoch 536/600\n",
      "900/900 [==============================] - 1s 687us/step - loss: 0.1612 - acc: 0.9400 - val_loss: 1.0181 - val_acc: 0.8000\n",
      "Epoch 537/600\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.1798 - acc: 0.9233 - val_loss: 1.1737 - val_acc: 0.7900\n",
      "Epoch 538/600\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.1566 - acc: 0.9344 - val_loss: 1.1813 - val_acc: 0.7800\n",
      "Epoch 539/600\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.1537 - acc: 0.9322 - val_loss: 1.2750 - val_acc: 0.7800\n",
      "Epoch 540/600\n",
      "900/900 [==============================] - 1s 657us/step - loss: 0.1763 - acc: 0.9389 - val_loss: 1.1674 - val_acc: 0.7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/600\n",
      "900/900 [==============================] - 1s 694us/step - loss: 0.1597 - acc: 0.9333 - val_loss: 1.2051 - val_acc: 0.8000\n",
      "Epoch 542/600\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.1599 - acc: 0.9356 - val_loss: 1.1983 - val_acc: 0.7800\n",
      "Epoch 543/600\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.1667 - acc: 0.9333 - val_loss: 1.2174 - val_acc: 0.7700\n",
      "Epoch 544/600\n",
      "900/900 [==============================] - 1s 797us/step - loss: 0.1408 - acc: 0.9422 - val_loss: 1.2428 - val_acc: 0.7700\n",
      "Epoch 545/600\n",
      "900/900 [==============================] - 1s 649us/step - loss: 0.1814 - acc: 0.9311 - val_loss: 1.1373 - val_acc: 0.7800\n",
      "Epoch 546/600\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.1612 - acc: 0.9456 - val_loss: 1.1053 - val_acc: 0.7900\n",
      "Epoch 547/600\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.1303 - acc: 0.9478 - val_loss: 1.3555 - val_acc: 0.7800\n",
      "Epoch 548/600\n",
      "900/900 [==============================] - 1s 818us/step - loss: 0.1389 - acc: 0.9478 - val_loss: 1.1659 - val_acc: 0.7800\n",
      "Epoch 549/600\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.1448 - acc: 0.9422 - val_loss: 1.0897 - val_acc: 0.8000\n",
      "Epoch 550/600\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.1393 - acc: 0.9478 - val_loss: 1.0470 - val_acc: 0.8300\n",
      "Epoch 551/600\n",
      "900/900 [==============================] - 1s 688us/step - loss: 0.1453 - acc: 0.9356 - val_loss: 1.1974 - val_acc: 0.7900\n",
      "Epoch 552/600\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.1589 - acc: 0.9411 - val_loss: 1.1944 - val_acc: 0.7900\n",
      "Epoch 553/600\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.1329 - acc: 0.9489 - val_loss: 1.3483 - val_acc: 0.7900\n",
      "Epoch 554/600\n",
      "900/900 [==============================] - 1s 677us/step - loss: 0.1534 - acc: 0.9367 - val_loss: 1.2316 - val_acc: 0.8000\n",
      "Epoch 555/600\n",
      "900/900 [==============================] - 1s 797us/step - loss: 0.1503 - acc: 0.9356 - val_loss: 1.1690 - val_acc: 0.7900\n",
      "Epoch 556/600\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.1421 - acc: 0.9422 - val_loss: 1.4388 - val_acc: 0.7700\n",
      "Epoch 557/600\n",
      "900/900 [==============================] - 1s 667us/step - loss: 0.1662 - acc: 0.9400 - val_loss: 1.1768 - val_acc: 0.7900\n",
      "Epoch 558/600\n",
      "900/900 [==============================] - 1s 832us/step - loss: 0.1686 - acc: 0.9389 - val_loss: 1.5024 - val_acc: 0.8000\n",
      "Epoch 559/600\n",
      "900/900 [==============================] - 1s 864us/step - loss: 0.1234 - acc: 0.9533 - val_loss: 1.2488 - val_acc: 0.8000\n",
      "Epoch 560/600\n",
      "900/900 [==============================] - 1s 799us/step - loss: 0.1386 - acc: 0.9567 - val_loss: 1.1811 - val_acc: 0.7800\n",
      "Epoch 561/600\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.1511 - acc: 0.9456 - val_loss: 1.2857 - val_acc: 0.7800\n",
      "Epoch 562/600\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.1576 - acc: 0.9356 - val_loss: 1.2576 - val_acc: 0.7900\n",
      "Epoch 563/600\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.1641 - acc: 0.9489 - val_loss: 1.1569 - val_acc: 0.7700\n",
      "Epoch 564/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.1335 - acc: 0.9511 - val_loss: 1.1377 - val_acc: 0.7900\n",
      "Epoch 565/600\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.1303 - acc: 0.9389 - val_loss: 1.0984 - val_acc: 0.7800\n",
      "Epoch 566/600\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.1575 - acc: 0.9400 - val_loss: 1.3298 - val_acc: 0.7900\n",
      "Epoch 567/600\n",
      "900/900 [==============================] - 1s 690us/step - loss: 0.1505 - acc: 0.9411 - val_loss: 1.2847 - val_acc: 0.7900\n",
      "Epoch 568/600\n",
      "900/900 [==============================] - 1s 665us/step - loss: 0.1469 - acc: 0.9356 - val_loss: 1.4428 - val_acc: 0.7800\n",
      "Epoch 569/600\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.1218 - acc: 0.9533 - val_loss: 1.4075 - val_acc: 0.8000\n",
      "Epoch 570/600\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.1615 - acc: 0.9344 - val_loss: 1.3742 - val_acc: 0.7800\n",
      "Epoch 571/600\n",
      "900/900 [==============================] - 1s 626us/step - loss: 0.1351 - acc: 0.9467 - val_loss: 1.4620 - val_acc: 0.7900\n",
      "Epoch 572/600\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.1532 - acc: 0.9311 - val_loss: 1.3612 - val_acc: 0.7800\n",
      "Epoch 573/600\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.1429 - acc: 0.9378 - val_loss: 1.2610 - val_acc: 0.8000\n",
      "Epoch 574/600\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.1403 - acc: 0.9489 - val_loss: 1.2387 - val_acc: 0.7900\n",
      "Epoch 575/600\n",
      "900/900 [==============================] - 1s 801us/step - loss: 0.1263 - acc: 0.9389 - val_loss: 1.2656 - val_acc: 0.8000\n",
      "Epoch 576/600\n",
      "900/900 [==============================] - 1s 816us/step - loss: 0.1616 - acc: 0.9444 - val_loss: 1.3572 - val_acc: 0.7700\n",
      "Epoch 577/600\n",
      "900/900 [==============================] - 1s 813us/step - loss: 0.1151 - acc: 0.9467 - val_loss: 1.2615 - val_acc: 0.7600\n",
      "Epoch 578/600\n",
      "900/900 [==============================] - 1s 827us/step - loss: 0.1492 - acc: 0.9433 - val_loss: 1.1718 - val_acc: 0.7900\n",
      "Epoch 579/600\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.1498 - acc: 0.9444 - val_loss: 1.3228 - val_acc: 0.7900\n",
      "Epoch 580/600\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.1378 - acc: 0.9500 - val_loss: 1.1460 - val_acc: 0.7500\n",
      "Epoch 581/600\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.1322 - acc: 0.9511 - val_loss: 1.4146 - val_acc: 0.7800\n",
      "Epoch 582/600\n",
      "900/900 [==============================] - 1s 795us/step - loss: 0.1560 - acc: 0.9389 - val_loss: 1.3288 - val_acc: 0.8000\n",
      "Epoch 583/600\n",
      "900/900 [==============================] - 1s 844us/step - loss: 0.1297 - acc: 0.9556 - val_loss: 1.2091 - val_acc: 0.7800\n",
      "Epoch 584/600\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.1550 - acc: 0.9356 - val_loss: 1.3239 - val_acc: 0.7900\n",
      "Epoch 585/600\n",
      "900/900 [==============================] - 1s 794us/step - loss: 0.1403 - acc: 0.9478 - val_loss: 1.2456 - val_acc: 0.7900\n",
      "Epoch 586/600\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.1455 - acc: 0.9467 - val_loss: 1.4317 - val_acc: 0.7900\n",
      "Epoch 587/600\n",
      "900/900 [==============================] - 1s 822us/step - loss: 0.1415 - acc: 0.9433 - val_loss: 1.4784 - val_acc: 0.7800\n",
      "Epoch 588/600\n",
      "900/900 [==============================] - 1s 867us/step - loss: 0.1291 - acc: 0.9500 - val_loss: 1.2487 - val_acc: 0.7800\n",
      "Epoch 589/600\n",
      "900/900 [==============================] - 1s 874us/step - loss: 0.1237 - acc: 0.9500 - val_loss: 1.3680 - val_acc: 0.7900\n",
      "Epoch 590/600\n",
      "900/900 [==============================] - 1s 840us/step - loss: 0.1527 - acc: 0.9389 - val_loss: 1.4416 - val_acc: 0.7600\n",
      "Epoch 591/600\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.1420 - acc: 0.9478 - val_loss: 1.3038 - val_acc: 0.7800\n",
      "Epoch 592/600\n",
      "900/900 [==============================] - 1s 809us/step - loss: 0.1354 - acc: 0.9433 - val_loss: 1.4113 - val_acc: 0.7800\n",
      "Epoch 593/600\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.1559 - acc: 0.9367 - val_loss: 1.2791 - val_acc: 0.7700\n",
      "Epoch 594/600\n",
      "900/900 [==============================] - 1s 878us/step - loss: 0.1222 - acc: 0.9456 - val_loss: 1.3767 - val_acc: 0.7600\n",
      "Epoch 595/600\n",
      "900/900 [==============================] - 1s 869us/step - loss: 0.1249 - acc: 0.9522 - val_loss: 1.3164 - val_acc: 0.7800\n",
      "Epoch 596/600\n",
      "900/900 [==============================] - 1s 865us/step - loss: 0.1557 - acc: 0.9367 - val_loss: 1.2707 - val_acc: 0.7800\n",
      "Epoch 597/600\n",
      "900/900 [==============================] - 1s 871us/step - loss: 0.1356 - acc: 0.9500 - val_loss: 1.2268 - val_acc: 0.7900\n",
      "Epoch 598/600\n",
      "900/900 [==============================] - 1s 866us/step - loss: 0.1256 - acc: 0.9500 - val_loss: 1.3310 - val_acc: 0.7800\n",
      "Epoch 599/600\n",
      "900/900 [==============================] - 1s 880us/step - loss: 0.1397 - acc: 0.9478 - val_loss: 1.2822 - val_acc: 0.7700\n",
      "Epoch 600/600\n",
      "900/900 [==============================] - 1s 873us/step - loss: 0.1529 - acc: 0.9467 - val_loss: 1.1258 - val_acc: 0.7900\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=30, kernel_initializer='glorot_normal', activation='selu'))\n",
    "model.add(AlphaDropout(.2))\n",
    "model.add(Dense(75, kernel_initializer='glorot_normal', activation='selu'))\n",
    "model.add(Dense(50, kernel_initializer='glorot_normal', activation='selu'))\n",
    "model.add(AlphaDropout(.2))\n",
    "model.add(Dense(25,  kernel_initializer='glorot_normal', activation='selu'))\n",
    "model.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='rmsprop')\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in skf.split(p_x_data, y_data):\n",
    "    model.fit_generator()\n",
    "    model.fit(mx.transform(x_data)[train_index,:],y_data[train_index,:], epochs=int(600),batch_size=16,verbose=1,validation_data=(mx.transform(x_data)[test_index,:],y_data[test_index,:]))\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 0.7135 - acc: 0.5414 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6624 - acc: 0.6539 - val_loss: 0.6557 - val_acc: 0.6200\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6340 - acc: 0.7367 - val_loss: 0.6213 - val_acc: 0.6800\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6299 - acc: 0.7086 - val_loss: 0.6143 - val_acc: 0.6700\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6148 - acc: 0.7141 - val_loss: 0.6185 - val_acc: 0.6700\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6042 - acc: 0.7016 - val_loss: 0.5856 - val_acc: 0.6900\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5871 - acc: 0.7359 - val_loss: 0.5988 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5832 - acc: 0.7289 - val_loss: 0.5682 - val_acc: 0.7100\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5722 - acc: 0.7320 - val_loss: 0.5660 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5609 - acc: 0.7281 - val_loss: 0.5557 - val_acc: 0.7300\n",
      "100/100 [==============================] - 0s 60us/step\n",
      "[0.5556761980056762, 0.73]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.6749 - acc: 0.6008 - val_loss: 0.6477 - val_acc: 0.7300\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6499 - acc: 0.6633 - val_loss: 0.6350 - val_acc: 0.6800\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6326 - acc: 0.7047 - val_loss: 0.6362 - val_acc: 0.6400\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6129 - acc: 0.7063 - val_loss: 0.6264 - val_acc: 0.6700\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5995 - acc: 0.7281 - val_loss: 0.6072 - val_acc: 0.6700\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5817 - acc: 0.7250 - val_loss: 0.6117 - val_acc: 0.6800\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5717 - acc: 0.7359 - val_loss: 0.5977 - val_acc: 0.6900\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5618 - acc: 0.7391 - val_loss: 0.6289 - val_acc: 0.6500\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5480 - acc: 0.7312 - val_loss: 0.6153 - val_acc: 0.6600\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5423 - acc: 0.7320 - val_loss: 0.5848 - val_acc: 0.7000\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "[0.5847760629653931, 0.7]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7014 - acc: 0.5242 - val_loss: 0.6754 - val_acc: 0.5900\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6743 - acc: 0.5969 - val_loss: 0.6491 - val_acc: 0.6900\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6578 - acc: 0.6422 - val_loss: 0.6397 - val_acc: 0.6900\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6362 - acc: 0.7117 - val_loss: 0.6215 - val_acc: 0.7000\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6161 - acc: 0.7320 - val_loss: 0.6060 - val_acc: 0.7100\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6085 - acc: 0.7109 - val_loss: 0.5908 - val_acc: 0.7400\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5973 - acc: 0.7047 - val_loss: 0.6094 - val_acc: 0.7200\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5955 - acc: 0.7047 - val_loss: 0.5619 - val_acc: 0.7400\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5804 - acc: 0.7281 - val_loss: 0.5703 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5576 - acc: 0.7492 - val_loss: 0.5553 - val_acc: 0.7600\n",
      "100/100 [==============================] - 0s 70us/step\n",
      "[0.5552676129341125, 0.76]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.6956 - acc: 0.5336 - val_loss: 0.6833 - val_acc: 0.5900\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6677 - acc: 0.6516 - val_loss: 0.6382 - val_acc: 0.7100\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6510 - acc: 0.6594 - val_loss: 0.6519 - val_acc: 0.6800\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6354 - acc: 0.6875 - val_loss: 0.6531 - val_acc: 0.6700\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6098 - acc: 0.7367 - val_loss: 0.6507 - val_acc: 0.6400\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5998 - acc: 0.7297 - val_loss: 0.6139 - val_acc: 0.7000\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5889 - acc: 0.7250 - val_loss: 0.6366 - val_acc: 0.6400\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5905 - acc: 0.7031 - val_loss: 0.6080 - val_acc: 0.6900\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5592 - acc: 0.7477 - val_loss: 0.6081 - val_acc: 0.6900\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5679 - acc: 0.7172 - val_loss: 0.5915 - val_acc: 0.7000\n",
      "100/100 [==============================] - 0s 70us/step\n",
      "[0.5915439558029175, 0.7]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.7112 - acc: 0.5234 - val_loss: 0.6638 - val_acc: 0.7100\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6765 - acc: 0.6164 - val_loss: 0.6606 - val_acc: 0.7100\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6539 - acc: 0.6961 - val_loss: 0.6704 - val_acc: 0.6000\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6461 - acc: 0.6844 - val_loss: 0.6226 - val_acc: 0.7300\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6267 - acc: 0.7180 - val_loss: 0.6192 - val_acc: 0.7200\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6121 - acc: 0.7219 - val_loss: 0.6045 - val_acc: 0.7300\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5905 - acc: 0.7375 - val_loss: 0.5698 - val_acc: 0.7900\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5865 - acc: 0.7211 - val_loss: 0.5621 - val_acc: 0.7600\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5665 - acc: 0.7453 - val_loss: 0.5656 - val_acc: 0.7400\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5828 - acc: 0.7055 - val_loss: 0.5586 - val_acc: 0.7500\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "[0.5586172008514404, 0.75]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.6987 - acc: 0.5156 - val_loss: 0.7407 - val_acc: 0.3000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6743 - acc: 0.5969 - val_loss: 0.6572 - val_acc: 0.6700\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6504 - acc: 0.7016 - val_loss: 0.6425 - val_acc: 0.6900\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6413 - acc: 0.6828 - val_loss: 0.6604 - val_acc: 0.6200\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6291 - acc: 0.6922 - val_loss: 0.6194 - val_acc: 0.7200\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6040 - acc: 0.7305 - val_loss: 0.6123 - val_acc: 0.7000\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5950 - acc: 0.7297 - val_loss: 0.5951 - val_acc: 0.7100\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5832 - acc: 0.7234 - val_loss: 0.6147 - val_acc: 0.6100\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5785 - acc: 0.7250 - val_loss: 0.6017 - val_acc: 0.6500\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5594 - acc: 0.7500 - val_loss: 0.5994 - val_acc: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 73us/step\n",
      "[0.5993511080741882, 0.64]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.6826 - acc: 0.5703 - val_loss: 0.6752 - val_acc: 0.6400\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6554 - acc: 0.6945 - val_loss: 0.6743 - val_acc: 0.6000\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6348 - acc: 0.6984 - val_loss: 0.6446 - val_acc: 0.6800\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6239 - acc: 0.7133 - val_loss: 0.6364 - val_acc: 0.6900\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6111 - acc: 0.6992 - val_loss: 0.6255 - val_acc: 0.6800\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5909 - acc: 0.7266 - val_loss: 0.6606 - val_acc: 0.6000\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5700 - acc: 0.7406 - val_loss: 0.6099 - val_acc: 0.6800\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5635 - acc: 0.7398 - val_loss: 0.5931 - val_acc: 0.7300\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5607 - acc: 0.7242 - val_loss: 0.6197 - val_acc: 0.6700\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5541 - acc: 0.7422 - val_loss: 0.6135 - val_acc: 0.6700\n",
      "100/100 [==============================] - 0s 52us/step\n",
      "[0.6135218358039856, 0.67]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.6813 - acc: 0.5797 - val_loss: 0.6220 - val_acc: 0.7200\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6667 - acc: 0.6516 - val_loss: 0.6537 - val_acc: 0.6500\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6514 - acc: 0.6609 - val_loss: 0.6105 - val_acc: 0.8100\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6312 - acc: 0.6992 - val_loss: 0.5846 - val_acc: 0.8100\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6213 - acc: 0.7016 - val_loss: 0.5992 - val_acc: 0.6900\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5976 - acc: 0.7289 - val_loss: 0.5540 - val_acc: 0.8100\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6103 - acc: 0.6922 - val_loss: 0.5568 - val_acc: 0.7700\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5801 - acc: 0.7203 - val_loss: 0.5643 - val_acc: 0.7300\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5791 - acc: 0.7141 - val_loss: 0.5469 - val_acc: 0.7400\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5626 - acc: 0.7344 - val_loss: 0.5376 - val_acc: 0.7600\n",
      "100/100 [==============================] - 0s 49us/step\n",
      "[0.5376492404937744, 0.76]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 0.6844 - acc: 0.5633 - val_loss: 0.6383 - val_acc: 0.7100\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6648 - acc: 0.6234 - val_loss: 0.6624 - val_acc: 0.6400\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6475 - acc: 0.6828 - val_loss: 0.6263 - val_acc: 0.7200\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6357 - acc: 0.6836 - val_loss: 0.6562 - val_acc: 0.6200\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6148 - acc: 0.7172 - val_loss: 0.6415 - val_acc: 0.6400\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6032 - acc: 0.7211 - val_loss: 0.5952 - val_acc: 0.7400\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5933 - acc: 0.7047 - val_loss: 0.5626 - val_acc: 0.7800\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5845 - acc: 0.7227 - val_loss: 0.5838 - val_acc: 0.7400\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5738 - acc: 0.7211 - val_loss: 0.5656 - val_acc: 0.7600\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5661 - acc: 0.7305 - val_loss: 0.5665 - val_acc: 0.7500\n",
      "100/100 [==============================] - 0s 59us/step\n",
      "[0.5664595699310303, 0.75]\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 0.6754 - acc: 0.6102 - val_loss: 0.6662 - val_acc: 0.6400\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6544 - acc: 0.6617 - val_loss: 0.6291 - val_acc: 0.7200\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6374 - acc: 0.7047 - val_loss: 0.6173 - val_acc: 0.7200\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6238 - acc: 0.7023 - val_loss: 0.6270 - val_acc: 0.6700\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6116 - acc: 0.6953 - val_loss: 0.6044 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5979 - acc: 0.7195 - val_loss: 0.5707 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5799 - acc: 0.7188 - val_loss: 0.5901 - val_acc: 0.6900\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5705 - acc: 0.7227 - val_loss: 0.5902 - val_acc: 0.7100\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5803 - acc: 0.6945 - val_loss: 0.5799 - val_acc: 0.6900\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5666 - acc: 0.7234 - val_loss: 0.5654 - val_acc: 0.7200\n",
      "100/100 [==============================] - 0s 57us/step\n",
      "[0.5653620719909668, 0.72]\n",
      "0.7179999999999999\n"
     ]
    }
   ],
   "source": [
    "sum_val_acc = 0\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "sgd = SGD(lr=0.3, momentum=0.7)\n",
    "for train_index, test_index in skf.split(x_data, y_data):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=30, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='rmsprop')\n",
    "    hist = model.fit_generator(data_generator(p_x_data[train_index,:],y_data[train_index,:],32),epochs=int(10),steps_per_epoch=40,validation_data=(mx.transform(x_data)[test_index,:],y_data[test_index,:]))\n",
    "    x = model.evaluate(mx.transform(x_data)[test_index,:],y_data[test_index,:])\n",
    "    print(x)\n",
    "#     hist = model.fit(mx.transform(x_data)[train_index,:],y_data[train_index,:], epochs=int(400),batch_size=len(train_index),verbose=0,validation_data=(mx.transform(x_data)[test_index,:],y_data[test_index,:]))\n",
    "    sum_val_acc += hist.history['val_acc'].pop()\n",
    "    del model\n",
    "print(sum_val_acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1.        , 0.11764706, 0.5       , 0.        , 0.        ,\n",
      "        1.        , 0.        , 0.        , 0.        , 0.07285133,\n",
      "        0.        , 0.5       , 1.        , 0.        , 1.        ,\n",
      "        0.        , 0.        , 0.        , 0.33333333, 1.        ,\n",
      "        0.        , 0.55357143, 0.        , 0.        , 1.        ,\n",
      "        0.        , 0.66666667, 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.11764706, 1.        , 0.        , 0.        ,\n",
      "        0.        , 1.        , 0.        , 0.        , 0.11450424,\n",
      "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
      "        0.        , 1.        , 0.        , 1.        , 1.        ,\n",
      "        0.        , 0.53571429, 0.        , 0.        , 1.        ,\n",
      "        0.        , 0.66666667, 0.        , 1.        , 0.        ],\n",
      "       [0.33333333, 0.82352941, 0.5       , 1.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.39385936,\n",
      "        0.25      , 0.25      , 1.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
      "        0.        , 0.08928571, 0.        , 0.        , 1.        ,\n",
      "        0.        , 1.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.02941176, 1.        , 1.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.18851106,\n",
      "        0.        , 0.5       , 0.        , 0.        , 1.        ,\n",
      "        0.        , 0.        , 0.        , 0.66666667, 1.        ,\n",
      "        0.        , 0.32142857, 0.        , 1.        , 0.        ,\n",
      "        0.66666667, 0.66666667, 1.        , 0.        , 0.        ],\n",
      "       [0.        , 0.08823529, 1.        , 1.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.04335864,\n",
      "        0.        , 0.75      , 1.        , 0.        , 1.        ,\n",
      "        0.        , 1.        , 0.        , 0.66666667, 0.        ,\n",
      "        0.        , 0.53571429, 0.        , 0.        , 1.        ,\n",
      "        0.33333333, 0.66666667, 0.        , 1.        , 0.        ],\n",
      "       [1.        , 0.20588235, 0.5       , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 1.        , 0.09354022,\n",
      "        0.        , 0.75      , 1.        , 0.        , 1.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.26785714, 1.        , 0.        , 1.        ,\n",
      "        0.33333333, 0.66666667, 0.        , 1.        , 0.        ],\n",
      "       [0.33333333, 0.23529412, 0.75      , 0.        , 1.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.37454605,\n",
      "        1.        , 0.75      , 0.66666667, 0.        , 1.        ,\n",
      "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "        0.        , 0.30357143, 1.        , 1.        , 0.        ,\n",
      "        0.33333333, 1.        , 1.        , 1.        , 0.        ],\n",
      "       [0.33333333, 0.11764706, 0.5       , 0.        , 0.        ,\n",
      "        0.        , 1.        , 0.        , 0.        , 0.04693518,\n",
      "        0.        , 0.75      , 1.        , 0.        , 1.        ,\n",
      "        0.        , 0.        , 1.        , 0.66666667, 1.        ,\n",
      "        0.        , 0.17857143, 0.        , 0.        , 1.        ,\n",
      "        0.33333333, 0.66666667, 0.        , 0.        , 1.        ],\n",
      "       [0.33333333, 0.38235294, 0.75      , 0.        , 0.        ,\n",
      "        0.        , 1.        , 0.        , 0.        , 0.09183449,\n",
      "        0.25      , 0.25      , 1.        , 0.        , 1.        ,\n",
      "        0.        , 0.        , 0.        , 0.66666667, 0.        ,\n",
      "        1.        , 0.19642857, 1.        , 0.        , 1.        ,\n",
      "        0.33333333, 1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.38235294, 1.        , 0.        , 0.        ,\n",
      "        0.        , 1.        , 0.        , 0.        , 0.23550127,\n",
      "        0.        , 0.75      , 1.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "        0.        , 0.125     , 0.        , 1.        , 0.        ,\n",
      "        0.        , 1.        , 0.        , 1.        , 0.        ]]), array([1, 1, 0, 1, 1, 1, 1, 1, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "for i in data_generator(p_x_data,y_data,10) :\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data,labels,batch_size) :\n",
    "    class_data = [[],[]]\n",
    "    for i,row in enumerate(data) :\n",
    "        if labels[i] == 0 :\n",
    "            class_data[0].append(list(row))\n",
    "        else :\n",
    "            class_data[1].append(list(row))\n",
    "    while True :\n",
    "        batch = []\n",
    "        batch_label = []\n",
    "        for _ in range(batch_size) :\n",
    "            choice = 1 if np.random.random() > .5 else 0\n",
    "            batch_label.append(choice)\n",
    "            batch.append(class_data[choice][np.random.randint(len(class_data[choice]))])\n",
    "        yield (np.array(batch),np.array(batch_label))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
