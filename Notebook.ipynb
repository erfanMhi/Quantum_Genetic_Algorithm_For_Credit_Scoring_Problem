{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Inspired Genetic Algorithm For Credit Scoring Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do List\n",
    "* Create Diffrent Version Of Algorithm : Diffrent Crossover,Mutation and ...p\n",
    "* Add Feature Restriction(Crossover and Population should be modified.)\n",
    "* Add Feature Preprocessing\n",
    "* MinMaxScaler +\n",
    "* Change the k and get the result again\n",
    "* Neural network optimization\n",
    "    * Using Diffrent Optimizers\n",
    "    * Use Diffrent Architecture\n",
    "* Speed Up Convergence\n",
    "    * Manipulating Population Number & Generation Number\n",
    "    * If Population Fitness didn't changed after N generation, end it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done So Far\n",
    "* All The Main Functions Implemented\n",
    "* all functions debugged\n",
    "* Whole Algorithm Implemented\n",
    "* MultiProcessing Added\n",
    "* Run Multipletimes and average them all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contents\n",
    "* Preconfiguration\n",
    "    * Importing Libraries\n",
    "    * Constants Decleration\n",
    "        * Genetic Algorithm Configurations\n",
    "        * Neural Network Configurations\n",
    "        * Reduced Features Announced By Credit Scorring Essay\n",
    "        * Datasets Path\n",
    "    * Tools Class Implementation\n",
    "    * Creating Types\n",
    "    * Qbit Class Implementation\n",
    "    * Reading Data\n",
    "    * Initialization\n",
    "    * Operators\n",
    "        * Converting To Bit\n",
    "        * Mutation\n",
    "        * Crossover\n",
    "        * Selection\n",
    "        * Rotation\n",
    "        * Catastroph\n",
    "        * Fitness Calculation\n",
    "        \n",
    "* Implementation\n",
    "    * Quantum Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from deap import tools\n",
    "from deap import base, creator\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing import Pool\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.optimizers import adam, SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants Decleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output'\n",
    "chromosome_file = 'chromosomes'\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# pop_size = 100\n",
    "# gen_num = 100 # it could be 300 too\n",
    "# n_max = 15\n",
    "# m_max = 25\n",
    "# pc = 0.9\n",
    "# pm = 0.01\n",
    "# pcc = (1 - pc) * random.random() + pc\n",
    "# pmm = (2*pm - pm) * random.random() + pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced Features Announced By Credit Scorring Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_feature_config = {\n",
    "    'IG': [ 0,  1,  2,  6,  9, 10, 11, 19, 20, 21, 22, 24],\n",
    "    'gain_ratio': [ 0,  1,  2,  4,  9, 10, 19, 20, 21, 22, 24, 29],\n",
    "    'correlation': [ 0,  1,  2,  4,  6,  9, 10, 11, 19, 20, 22, 24],\n",
    "    'voting': [ 0,  1,  2,  9, 10, 19, 20, 22, 24],\n",
    "    'current_solution': [ 0,  1,  2,  3, 10, 12, 13, 14, 17, 19, 20, 27, 29]\n",
    "}\n",
    "reduced_feature_subset = []\n",
    "for key in reduced_feature_config : \n",
    "    reduced_feature_subset += reduced_feature_config[key]\n",
    "reduced_feature_subset_rank = {}\n",
    "for feature in reduced_feature_subset:\n",
    "    if feature in reduced_feature_subset_rank:\n",
    "        reduced_feature_subset_rank[feature] += 1\n",
    "    else :\n",
    "        reduced_feature_subset_rank[feature] = 1\n",
    "mask = np.zeros(30)\n",
    "for key in reduced_feature_subset_rank :\n",
    "    mask[key] = reduced_feature_subset_rank[key]\n",
    "reduced_feature_subset = sorted(list(set(reduced_feature_subset)))\n",
    "mask += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetic Algorithm Configurations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0.9\n",
    "pm = 0.01\n",
    "genetic_config = { \n",
    "    'max_feature_num': 12,\n",
    "    'min_feature_num': 5,\n",
    "    'pop_size': 100,\n",
    "    'iter_num': 100,\n",
    "    'n_max': 15,\n",
    "    'm_max': 25,\n",
    "    'pm': 0.01,\n",
    "    'pc': 0.9,\n",
    "    'pmm': (2*pm - pm) * random.random() + pm,\n",
    "    'pcc': (1 - pc) * random.random() + pc,\n",
    "    'mask_best_num':1,\n",
    "    'mask_evapuration_rate':.1,\n",
    "    'mask_update_rate':.5,\n",
    "    'epsilon':1,\n",
    "    'chrom_mask': mask\n",
    "#     'crossover' : '',\n",
    "#     'mutation' : '',\n",
    "#     'rotation' : True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m': 0.7, 'train_cycles': 600, 'lr': 0.3}\n"
     ]
    }
   ],
   "source": [
    "nn_config = {\n",
    "    # 'lr': np.random.uniform(0.3, 1.0),\n",
    "    # 'train_cycles': np.random.uniform(300, 600),\n",
    "    # 'm': np.random.uniform(0.2, 0.7)\n",
    "    'm':.7,\n",
    "    'train_cycles':600,\n",
    "    'lr': .3\n",
    "}\n",
    "print(nn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data'\n",
    "german_data = os.path.join(data_root,'GermanCreditInput.xls')\n",
    "german_label = os.path.join(data_root,'GermanCreditOutputClass1columnknn.xls')\n",
    "australian_dataset = os.path.join(data_root,'australian dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tools :\n",
    "    \n",
    "    data_root = ''\n",
    "    root_url = ''\n",
    "    chromosomes = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def download_progress_hook(count, blockSize, totalSize):\n",
    "        \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "        slow internet connections. Reports every 5% change in download progress.\"\"\"\n",
    "        global last_percent_reported\n",
    "        percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "        if last_percent_reported != percent:\n",
    "            if percent % 5 == 0:\n",
    "                sys.stdout.write(\"%s%%\" % percent)\n",
    "                sys.stdout.flush()\n",
    "            else:\n",
    "                sys.stdout.write(\".\")\n",
    "                sys.stdout.flush()\n",
    "            last_percent_reported = percent\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_df(filename, expected_bytes=None, force=False):\n",
    "        \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "        dest_filename = os.path.join(Tools.data_root, filename)\n",
    "        direc = dest_filename[:dest_filename.rfind('/')]\n",
    "        if not os.path.exists(direc):\n",
    "            os.makedirs(direc)\n",
    "        if force or not os.path.exists(dest_filename):\n",
    "            print('Attempting to download:', filename) \n",
    "            filename, _ = urlretrieve(Tools.root_url + filename, dest_filename, reporthook=Tools.download_progress_hook)\n",
    "            print('\\nDownload Complete!')        \n",
    "        return np.array(pd.read_csv(filename, header=None))\n",
    "    \n",
    "    @staticmethod\n",
    "    def keras_model(input_dim,hiddenNum=40,lr=.1,m=.5) :\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hiddenNum, input_dim=input_dim, kernel_initializer='normal', activation='sigmoid'))\n",
    "        model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "        sgd = SGD(lr=lr, momentum=m)\n",
    "        # loss could be \"mse\" too\n",
    "        model.compile(loss='binary_crossentropy',metrics=['accuracy','binary_accuracy'],optimizer=sgd)\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_to_file(path,data) :\n",
    "        with open(path + '.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    @staticmethod    \n",
    "    def load_from_file(path) :\n",
    "        with open(path + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qbit Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qbit :\n",
    "    def __init__(self) :\n",
    "        self.a = random.random()\n",
    "        self.b = np.sqrt(1 - self.a**2)\n",
    "        self.bit = None\n",
    "    \n",
    "    def __str__(self) :\n",
    "        return '({}, {})'.format(self.a,self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading German Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape : (1000, 30)\n",
      "Dataset Labels Shape : (1000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(pd.read_excel(german_data,header=None))\n",
    "y_data = np.array(pd.read_excel(german_label,header=None))\n",
    "mx = MinMaxScaler()\n",
    "mx.fit(x_data)\n",
    "x_data = mx.transform(x_data)\n",
    "print('Dataset Shape : {}\\nDataset Labels Shape : {}'.format(x_data.shape,y_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attribute\", Qbit)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attribute, n=x_data.shape[1]) # Length of each chromosome : Number of Features of Dataset\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting To Bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toBit(ind) :\n",
    "    \"transform qbit to zero or one\"\n",
    "    for qb in ind :\n",
    "        if np.random.random() < qb.a**2 :\n",
    "            qb.bit = 0\n",
    "        else :\n",
    "            qb.bit = 1\n",
    "    return ind\n",
    "toolbox.register(\"toBit\",toBit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(ind) :\n",
    "    rnd = np.random.randint(len(ind))\n",
    "    ind[rnd].a,ind[rnd].b = ind[rnd].b,ind[rnd].a\n",
    "    return ind\n",
    "toolbox.register(\"mutate\", mutate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"mate\", tools.cxTwoPoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(ind,b_ind,isGreater) :\n",
    "    for qb,b_qb in zip(ind,b_ind) :\n",
    "        dt = 0\n",
    "        sign = 0\n",
    "        ri = qb.bit\n",
    "        bi = b_qb.bit\n",
    "        positive = qb.a * qb.b > 0\n",
    "        aZero = not qb.a\n",
    "        bZero = not qb.b\n",
    "        # initializing angle and sign of rotation \n",
    "        if(isGreater) :\n",
    "            if not ri and bi :\n",
    "                dt = np.pi * .05\n",
    "                if aZero :\n",
    "                    sign = 1\n",
    "                elif bZero :\n",
    "                    sign = 0\n",
    "                elif positive :\n",
    "                    sign = -1\n",
    "                else :\n",
    "                    sign = 1\n",
    "            elif ri and not bi :\n",
    "                dt = np.pi * .025\n",
    "                if aZero :\n",
    "                    sign = 0\n",
    "                elif bZero :\n",
    "                    sign = 1\n",
    "                elif positive :\n",
    "                    sign = 1\n",
    "                else :\n",
    "                    sign = -1\n",
    "            elif ri and bi :\n",
    "                dt = np.pi * .025\n",
    "                if aZero :\n",
    "                    sign = 0\n",
    "                elif bZero :\n",
    "                    sign = 1\n",
    "                elif positive :\n",
    "                    sign = 1\n",
    "                else :\n",
    "                    sign = -1\n",
    "        else :\n",
    "            if ri and not bi :\n",
    "                dt = np.pi * .01\n",
    "                if aZero :\n",
    "                    sign = 1\n",
    "                elif bZero :\n",
    "                    sign = 0\n",
    "                elif positive :\n",
    "                    sign = -1\n",
    "                else :\n",
    "                    sign = 1\n",
    "            elif ri and bi :\n",
    "                dt = np.pi * .005\n",
    "                if aZero :\n",
    "                    sign = 0\n",
    "                elif bZero :\n",
    "                    sign = 1\n",
    "                elif positive :\n",
    "                    sign = 1\n",
    "                else :\n",
    "                    sign = -1\n",
    "\n",
    "        t = sign * dt\n",
    "        qb.a,qb.b = np.dot(\n",
    "            np.array([[np.cos(t),-np.sin(t)],[np.sin(t),np.cos(t)]]),np.array([qb.a,qb.b])\n",
    "        )\n",
    "toolbox.register(\"rotate\", rotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ind,X,Y,train_cycles=600,lr=.3,m=.7) :\n",
    "    \"\"\"Train one layer feedforward neural network\n",
    "    Args :\n",
    "       X : training data\n",
    "       Y : training label\n",
    "       hiddenNum : number of hidden units of hidden layer\n",
    "       trainCycles : number of training cycles\n",
    "       lr : learning rate of nueral network\n",
    "       m: momentum of neural network\n",
    "    Returns :\n",
    "       'float' accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    sel_features = np.array(ind).astype(np.int32)\n",
    "    hiddenNum = len(sel_features) + np.sum(sel_features)\n",
    "    string_arr = ''.join(map(str, 1*sel_features))\n",
    "    sum_val_acc = 0\n",
    "    p_X = X[:,sel_features==1]\n",
    "    if string_arr not in Tools.chromosomes :\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "            model = Tools.keras_model(np.sum(sel_features),int(hiddenNum),lr,m)\n",
    "            hist = model.fit(p_X[train_index,:],Y[train_index,:], validation_data=(p_X[test_index,:],Y[test_index,:]),epochs=int(train_cycles),batch_size=int(X.shape[0]),verbose=0)\n",
    "            ev = model.evaluate(p_X[test_index,:],Y[test_index,:],verbose=0)\n",
    "            sum_val_acc += ev[1]\n",
    "            del model\n",
    "        Tools.chromosomes[string_arr] = sum_val_acc/10\n",
    "    return (Tools.chromosomes[string_arr],)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate,X=x_data,Y=y_data,**nn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(pop,pop_size) :    \n",
    "    # Roulette selection\n",
    "    offsprings = list(map(toolbox.clone,tools.selRoulette(pop,pop_size)))\n",
    "    # Elite selection\n",
    "    max_os_fit = np.max([ind.fitness.values[0] for ind in offsprings])\n",
    "    max_pop_fit = np.max([ind.fitness.values[0] for ind in pop])\n",
    "    replace_choices = list(range(pop_size))\n",
    "    \n",
    "    if max_pop_fit > max_os_fit :\n",
    "        for ind in sorted(pop, key=lambda x: x.fitness.values[0],reverse=True) :\n",
    "            if ind.fitness.values[0] > max_os_fit :\n",
    "                choice = np.random.choice(replace_choices)\n",
    "                offsprings[choice] = toolbox.clone(ind)\n",
    "                replace_choices.remove(choice) # To Stop replacing the best ones that we already replaced\n",
    "            else :\n",
    "                break;\n",
    "                \n",
    "    return offsprings \n",
    "\n",
    "toolbox.register(\"select\", select, pop_size=genetic_config['pop_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catastroph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catastrophe(best_ind,pop_size) :\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    pop[np.random.randint(0,pop_size)] = toolbox.clone(best_ind)\n",
    "    return pop\n",
    "toolbox.register(\"catastrophe\", catastrophe, pop_size=genetic_config['pop_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask update and collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_update(mask,best_ind,update_rate=.5,evapuration_rate=.1,inline=True) :\n",
    "    for i in range(len(mask)) :\n",
    "        mask[i] *= (1-evapuration_rate)\n",
    "        mask[i] += best_ind[i].bit*update_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_collapse(mask,epsilon=1) :\n",
    "    collapsed_mask = np.ndarray(len(mask))\n",
    "    max_val = max(mask) +epsilon\n",
    "    for i in range(len(mask)) :\n",
    "        collapsed_mask[i] = 1 if np.random.random() < mask[i]/max_val else 0\n",
    "    return collapsed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Whole Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pop(pop,collapsed_mask=None,multiprocessing=False,workers=20) :\n",
    "    best_ind = None\n",
    "    # Collapsing Individual Bits\n",
    "    for i,ind in enumerate(pop):\n",
    "        toolbox.toBit(ind)\n",
    "    # Masking Individual Bit Values\n",
    "    \n",
    "    if type(collapsed_mask) != type(None):\n",
    "        masked_pop = [[qb.bit and bit for qb,bit in zip(ind,collapsed_mask)] for ind in pop]\n",
    "    else :\n",
    "        masked_pop = [[qb.bit for qb in ind] for ind in pop]\n",
    "    print(np.sum([[qb.bit for qb in ind] for ind in pop],axis=1))\n",
    "    print(np.sum(masked_pop,axis=1))\n",
    "    if multiprocessing :\n",
    "        fitnesses = None\n",
    "        with contextlib.closing(Pool(processes=workers)) as pool:\n",
    "            fitnesses = pool.map_async(toolbox.evaluate, (ind for ind in masked_pop))\n",
    "            fitnesses = fitnesses.get()\n",
    "        for ind,fitness in zip(pop,fitnesses):\n",
    "            ind.fitness.values = fitness\n",
    "            if not best_ind or best_ind.fitness.values[0] < ind.fitness.values[0] :\n",
    "                best_ind = ind\n",
    "        Tools.save_to_file(chromosome_file,Tools.chromosomes)\n",
    "        with open('fitnesses.txt','a') as f :\n",
    "            f.write(str(fitnesses) + '\\n')\n",
    "    else :\n",
    "        # Evaluate Individual\n",
    "        for ind,mask_ind,i in zip(pop,masked_pop,range(len(pop))):\n",
    "            print('%{}'.format(float(i)/len(pop)))\n",
    "            ind.fitness.values = toolbox.evaluate(mask_ind)\n",
    "            if not best_ind or best_ind.fitness.values[0] < ind.fitness.values[0] :\n",
    "                best_ind = ind\n",
    "            if i % 10 == 0 :\n",
    "                Tools.save_to_file(chromosome_file,Tools.chromosomes)\n",
    "    return best_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pop_size,iter_num,n_max,m_max,\n",
    "        max_feature_num,min_feature_num,\n",
    "        pm,pc,pmm,pcc):\n",
    "    \n",
    "    best_fits = np.array([])\n",
    "    best_same_iter = 0\n",
    "    best_ind = None\n",
    "    current_best_ind = None\n",
    "    \n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    # Evaluate the entire population\n",
    "    for i,ind in enumerate(pop):\n",
    "        print('%{}'.format(float(i)/pop_size))\n",
    "        toolbox.toBit(ind)\n",
    "        ind.fitness.values = toolbox.evaluate(ind)\n",
    "        if not best_ind or best_ind.fitness.values[0] < ind.fitness.values[0] :\n",
    "            best_ind = ind\n",
    "            current_best_ind = ind\n",
    "    best_fits = np.append(best_fits,best_ind.fitness.values[0])\n",
    "        \n",
    "    for generation in range(1,iter_num) :   \n",
    "        print('--------------------generation : {} ------------------'.format(generation))\n",
    "        print('best fitness : {}'.format(best_ind.fitness.values[0]))\n",
    "        print('best current fit : {}'.format(current_best_ind.fitness.values[0]))\n",
    "        if best_same_iter < n_max :\n",
    "            offspring = toolbox.select(pop)\n",
    "            \n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < pc:\n",
    "                    toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "                    \n",
    "            # Apply mutation on the offspring      \n",
    "            for mutant in offspring:\n",
    "                if random.random() < pm:\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate Individual \n",
    "            current_best_ind = None\n",
    "            for i,ind in enumerate(offspring):\n",
    "                print('%{}'.format(float(i)/pop_size))\n",
    "                toolbox.toBit(ind)\n",
    "                ind.fitness.values = toolbox.evaluate(ind)\n",
    "                if not current_best_ind or current_best_ind.fitness.values[0] < ind.fitness.values[0] :\n",
    "                    current_best_ind = ind\n",
    "            \n",
    "            if current_best_ind.fitness.values[0] > best_ind.fitness.values[0] :\n",
    "                best_ind = toolbox.clone(current_best_ind)\n",
    "                best_same_iter = 0\n",
    "            if best_same_iter < m_max :\n",
    "                for ind in offspring :\n",
    "                    toolbox.rotate(ind,best_ind,best_ind.fitness.values[0] > ind.fitness.values[0])\n",
    "            else :\n",
    "                offspring[:] = toolbox.catastrophe(best_ind)\n",
    "                best_same_iter = 0\n",
    "        else :\n",
    "            offspring = toolbox.select(pop)\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < pcc:\n",
    "                    toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring      \n",
    "            for mutant in offspring:\n",
    "                if random.random() < pmm:\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate Individual \n",
    "            current_best_ind = None\n",
    "            for ind in offspring:\n",
    "                toolbox.toBit(ind)\n",
    "                ind.fitness.values = toolbox.evaluate(ind)\n",
    "                if not current_best_ind or current_best_ind.fitness.values[0] < ind.fitness.values[0] :\n",
    "                    current_best_ind = ind\n",
    "\n",
    "            if current_best_ind.fitness.values[0] > best_ind.fitness.values[0] :\n",
    "                best_ind = toolbox.clone(current_best_ind)\n",
    "                best_same_iter = 0\n",
    "            if best_same_iter < m_max :\n",
    "                for ind in offspring :\n",
    "                    toolbox.rotate(ind,best_ind,best_ind.fitness.values[0] > ind.fitness.values[0])\n",
    "            else :\n",
    "                offspring[:] = toolbox.catastrophe(best_ind)\n",
    "                best_same_iter = 0\n",
    "                \n",
    "        pop[:] = offspring\n",
    "        # Evaluate Individual \n",
    "        current_best_ind = None\n",
    "        for i,ind in enumerate(offspring):\n",
    "            print('%{}'.format(float(i)/pop_size))\n",
    "            toolbox.toBit(ind)\n",
    "            ind.fitness.values = toolbox.evaluate(ind)\n",
    "            if not current_best_ind or current_best_ind.fitness.values[0] < ind.fitness.values[0] :\n",
    "                current_best_ind = ind\n",
    "            \n",
    "        best_fits = np.append(best_fits,current_best_ind.fitness.values[0])\n",
    "        if current_best_ind.fitness.values[0] > best_ind.fitness.values[0] :\n",
    "            best_ind = toolbox.clone(current_best_ind)\n",
    "            best_same_iter = 0\n",
    "        else :\n",
    "            best_same_iter += 1\n",
    "    return best_fits,best_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum MultiProcess Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess_main(pop_size,iter_num,n_max,m_max,\n",
    "                    max_feature_num,min_feature_num,\n",
    "                    pm,pc,pmm,pcc,chrom_mask,mask_best_num=1,\n",
    "                    mask_evapuration_rate=.1,mask_update_rate=.5,\n",
    "                    epsilon=1,multiprocessing=False,workers=20):\n",
    "    if os.path.exists(chromosome_file+'.pkl') :\n",
    "        Tools.chromosomes = Tools.load_from_file(chromosome_file)\n",
    "        print('chromosomes loaded : {}'.format(Tools.chromosomes))\n",
    "    best_fits = np.array([])\n",
    "    best_same_iter = 0\n",
    "    best_ind = None\n",
    "    current_best_ind = None\n",
    "    mask = copy.deepcopy(chrom_mask)\n",
    "    \n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    # Callapse Mask\n",
    "    collapsed_mask = mask_collapse(mask,epsilon)\n",
    "    print(collapsed_mask)\n",
    "    # Evaluating whole population\n",
    "    best_ind = current_best_ind = evaluate_pop(pop,collapsed_mask,multiprocessing,workers)\n",
    "    \n",
    "    # Updating And Evapurating Mask Values\n",
    "    mask_update(mask,best_ind,mask_evapuration_rate=mask_evapuration_rate,mask_update_rate=mask_update_rate)\n",
    "    best_fits = np.append(best_fits,best_ind.fitness.values[0])\n",
    "    \n",
    "    for generation in range(1,iter_num) :   \n",
    "        print('--------------------generation : {} ------------------'.format(generation))\n",
    "        print('best fitness : {}'.format(best_ind.fitness.values[0]))\n",
    "        print('best current fit : {}'.format(current_best_ind.fitness.values[0]))\n",
    "        if best_same_iter < n_max :\n",
    "            offspring = toolbox.select(pop)\n",
    "            \n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < pc:\n",
    "                    toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "                    \n",
    "            # Apply mutation on the offspring      \n",
    "            for mutant in offspring:\n",
    "                if random.random() < pm:\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            start = time.time()\n",
    "            \n",
    "            # Callapse Mask\n",
    "            collapsed_mask = mask_collapse(mask,epsilon)\n",
    "            \n",
    "            # Evaluating whole population\n",
    "            current_best_ind = evaluate_pop(pop,collapsed_mask,multiprocessing,workers)\n",
    "            \n",
    "            # Updating And Evapurating Mask Values\n",
    "            mask_update(mask,best_ind,mask_evapuration_rate=mask_evapuration_rate,mask_update_rate=mask_update_rate)\n",
    "            print('First Evaluation Time : {}'.format(time.time() - start))\n",
    "            if current_best_ind.fitness.values[0] > best_ind.fitness.values[0] :\n",
    "                best_ind = toolbox.clone(current_best_ind)\n",
    "                best_same_iter = 0\n",
    "            if best_same_iter < m_max :\n",
    "                for ind in offspring :\n",
    "                    toolbox.rotate(ind,best_ind,best_ind.fitness.values[0] > ind.fitness.values[0])\n",
    "            else :\n",
    "                offspring[:] = toolbox.catastrophe(best_ind)\n",
    "                best_same_iter = 0\n",
    "        else :\n",
    "            offspring = toolbox.select(pop)\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < pcc:\n",
    "                    toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring      \n",
    "            for mutant in offspring:\n",
    "                if random.random() < pmm:\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "            \n",
    "            start = time.time()\n",
    "            current_best_ind = None\n",
    "            # Callapse Mask\n",
    "            collapsed_mask = mask_collapse(mask,epsilon)\n",
    "            \n",
    "            # Evaluating whole population\n",
    "            current_best_ind = evaluate_pop(pop,collapsed_mask,multiprocessing,workers)\n",
    "            \n",
    "            # Updating And Evapurating Mask Values\n",
    "            mask_update(mask,best_ind,mask_evapuration_rate=mask_evapuration_rate,mask_update_rate=mask_update_rate)\n",
    "            print('First Evaluation Time : {}'.format(time.time() - start))\n",
    "            if current_best_ind.fitness.values[0] > best_ind.fitness.values[0] :\n",
    "                best_ind = toolbox.clone(current_best_ind)\n",
    "                best_same_iter = 0\n",
    "            if best_same_iter < m_max :\n",
    "                for ind in offspring :\n",
    "                    toolbox.rotate(ind,best_ind,best_ind.fitness.values[0] > ind.fitness.values[0])\n",
    "            else :\n",
    "                offspring[:] = toolbox.catastrophe(best_ind)\n",
    "                best_same_iter = 0\n",
    "                \n",
    "        pop[:] = offspring\n",
    "\n",
    "        # Evaluate Individual \n",
    "        start = time.time()\n",
    "        \n",
    "        # Callapse Mask\n",
    "        collapsed_mask = mask_collapse(mask,epsilon)\n",
    "\n",
    "        # Evaluating whole population\n",
    "        current_best_ind = evaluate_pop(pop,collapsed_mask,multiprocessing,workers)\n",
    "        \n",
    "        # Updating And Evapurating Mask Values\n",
    "        mask_update(mask,best_ind,mask_evapuration_rate=mask_evapuration_rate,mask_update_rate=mask_update_rate)\n",
    "        print('Second Evaluation Time : {}'.format(time.time() - start))    \n",
    "        best_fits = np.append(best_fits,current_best_ind.fitness.values[0])\n",
    "        if current_best_ind.fitness.values[0] > best_ind.fitness.values[0] :\n",
    "            best_ind = toolbox.clone(current_best_ind)\n",
    "            best_same_iter = 0\n",
    "        else :\n",
    "            best_same_iter += 1\n",
    "    return best_fits,best_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_run(genetic_config,number_of_run=10) :\n",
    "    if os.path.exists(chromosome_file+'.pkl') :\n",
    "        Tools.chromosomes = Tools.load_from_file(chromosome_file)\n",
    "    out = [None for _ in range(number_of_run)]\n",
    "    for i in range(number_of_run) :\n",
    "        out[i] = multiprocess_main(**genetic_config)\n",
    "        print('{} run ended with fitness : {} '.format(i,out[i]))\n",
    "        Tools.save_to_file('{}({})'.format(output_file,i),out[i])\n",
    "    return np.average([o[1].fitness.values[0] for o in out]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromosomes loaded : {'100000100100000001111000100111': 0.726}\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0.]\n",
      "[21 18 20 18 20 17 21 19 14 19 18 22 18 23 19 21 20 21 18 17 20 20 20 18\n",
      " 22 20 14 20 21 19 18 16 17 24 23 21 17 20 20 21 21 18 15 14 18 26 19 21\n",
      " 19 18 21 16 17 19 20 23 19 18 23 18 18 17 17 20 25 21 22 16 18 20 19 17\n",
      " 20 21 21 16 19 20 23 18 21 16 22 18 20 23 19 19 20 20 22 20 18 20 23 22\n",
      " 24 16 23 24]\n",
      "[ 7.  7.  4.  4.  7.  7.  8.  6.  6.  7.  5.  8.  5.  7.  8.  7.  8.  7.\n",
      "  6.  3.  7.  8.  7.  6.  8.  7.  6.  4.  7.  3.  6.  5.  5.  9.  8. 10.\n",
      "  4.  6.  5.  8.  9.  7.  6.  4.  7.  8.  4.  7.  8.  7.  4.  6.  5.  6.\n",
      "  7.  8.  6.  6.  8.  6.  7.  5.  5.  7.  8.  7.  7.  6.  5.  9.  7.  6.\n",
      "  8.  6.  7.  8.  7.  7.  9.  8.  8.  5.  7.  7.  7.  9.  6.  6.  8.  7.\n",
      "  8.  5.  4.  7.  9.  9.  8.  5.  7.  8.]\n",
      "%0.0\n",
      "{'100000100100000001111000100111': 0.726, '011000100100000100010000000100': 0.718}\n",
      "0.718\n",
      "%0.01\n",
      "{'100000100100000001111000100111': 0.726, '011000100100000100010000000100': 0.718, '011000100010000100010000000100': 0.7269999999999999}\n",
      "0.7269999999999999\n",
      "%0.02\n",
      "{'100000100100000001111000100111': 0.726, '011000100100000100010000000100': 0.718, '011000100010000100010000000100': 0.7269999999999999, '100000000000000000010010000100': 0.7080000000000001}\n",
      "0.7080000000000001\n",
      "%0.03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-a6589ddf0d97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocess_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgenetic_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mTools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-101-9254e036352f>\u001b[0m in \u001b[0;36mmultiprocess_main\u001b[1;34m(pop_size, iter_num, n_max, m_max, max_feature_num, min_feature_num, pm, pc, pmm, pcc, chrom_mask, mask_best_num, mask_evapuration_rate, mask_update_rate, epsilon, multiprocessing, workers)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollapsed_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Evaluating whole population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mbest_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_best_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_pop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcollapsed_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Updating And Evapurating Mask Values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-514c0e1d3387>\u001b[0m in \u001b[0;36mevaluate_pop\u001b[1;34m(pop, collapsed_mask, multiprocessing, workers)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_ind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmasked_pop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbest_ind\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbest_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mbest_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-925b601174fd>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(ind, X, Y, train_cycles, lr, m)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhiddenNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cycles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#             print(hist.history['val_acc'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2652\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2653\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2654\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2655\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    out = multiprocess_main(**genetic_config,multiprocessing=True)\n",
    "    Tools.save_to_file(output_file,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__' :\n",
    "#     out = multiple_run(genetic_config)\n",
    "#     print('Average is : {}'.format(out))\n",
    "#     Tools.save_to_file('multi_run_' + output_file,out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
